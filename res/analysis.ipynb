{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:48.981423758Z",
     "start_time": "2023-06-23T15:11:48.938171436Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def find_upper_bound(mu, std, alpha=0.95):\n",
    "    z_value = norm.ppf(alpha)\n",
    "    return mu + std * z_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:49.110555294Z",
     "start_time": "2023-06-23T15:11:49.102273545Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "gpu_conv_value = 0.00021648585046\n",
    "gpu_no_norm_conv_value = 6958.933333333333333\n",
    "per_unit_energy_cons = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:49.344860608Z",
     "start_time": "2023-06-23T15:11:49.291132397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv(\"../saved_data/ali20/ali20_g.csv\")\n",
    "g_truth = original_dataset[\"avggpu\"].values[-2582:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:49.484762930Z",
     "start_time": "2023-06-23T15:11:49.460882100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "  model  pred_gpu  pred_std  true_norm_gpu      true_gpu  true_n_gpu  \\\n0  HBNN  0.792370  0.058169       0.804885  2.918980e+07        3718   \n1  HBNN  0.787413  0.058161       0.814360  2.940805e+07        3762   \n\n      ub_95  pred_n_gpu_95  \n0  0.888050           4103  \n1  0.883079           4080  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HBNN</td>\n      <td>0.792370</td>\n      <td>0.058169</td>\n      <td>0.804885</td>\n      <td>2.918980e+07</td>\n      <td>3718</td>\n      <td>0.888050</td>\n      <td>4103</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HBNN</td>\n      <td>0.787413</td>\n      <td>0.058161</td>\n      <td>0.814360</td>\n      <td>2.940805e+07</td>\n      <td>3762</td>\n      <td>0.883079</td>\n      <td>4080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbnn_results = pd.read_csv(\"output_HBNN-ali20_g-gpu-w288-h2.csv\")\n",
    "hbnn_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "hbnn_results[\"true_gpu\"] = g_truth\n",
    "hbnn_results[\"model\"] = [\"HBNN\" for i in range(len(hbnn_results))]\n",
    "hbnn_results.rename(columns={\"avggpu\": \"pred_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = hbnn_results.pop('model')\n",
    "hbnn_results.insert(0, 'model', first_column)\n",
    "hbnn_results[\"true_n_gpu\"] = hbnn_results.apply(lambda row: math.ceil(row[\"true_norm_gpu\"]/gpu_conv_value), axis=1)\n",
    "hbnn_results[\"ub_95\"] = hbnn_results.apply(lambda row: find_upper_bound(row[\"pred_gpu\"], row[\"pred_std\"], alpha=0.95), axis=1)\n",
    "hbnn_results[\"pred_n_gpu_95\"] = hbnn_results.apply(lambda row: math.ceil(row[\"ub_95\"]/gpu_conv_value), axis=1)\n",
    "hbnn_results.to_csv(\"scenarios/hbnn_results.csv\")\n",
    "hbnn_results.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:50.022015735Z",
     "start_time": "2023-06-23T15:11:49.650130228Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "          pred_gpu     pred_std  true_norm_gpu      true_gpu   true_n_gpu  \\\ncount  2582.000000  2582.000000    2582.000000  2.582000e+03  2582.000000   \nmean      0.357420     0.049786       0.328949  1.822752e+07  1519.997289   \nstd       0.187234     0.007063       0.232520  5.355664e+06  1074.064784   \nmin       0.109442     0.016079      -0.172291  6.682396e+06  -795.000000   \n25%       0.143482     0.046260       0.106536  1.310465e+07   492.250000   \n50%       0.372455     0.049210       0.362540  1.900122e+07  1675.000000   \n75%       0.516378     0.052960       0.519670  2.262042e+07  2400.750000   \nmax       0.825197     0.110551       0.915283  3.173261e+07  4228.000000   \n\n             ub_95  pred_n_gpu_95  \ncount  2582.000000    2582.000000  \nmean      0.439311    2029.774981  \nstd       0.189360     874.695920  \nmin       0.183581     849.000000  \n25%       0.230175    1064.000000  \n50%       0.449472    2076.500000  \n75%       0.599429    2769.000000  \nmax       0.918887    4245.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.357420</td>\n      <td>0.049786</td>\n      <td>0.328949</td>\n      <td>1.822752e+07</td>\n      <td>1519.997289</td>\n      <td>0.439311</td>\n      <td>2029.774981</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.187234</td>\n      <td>0.007063</td>\n      <td>0.232520</td>\n      <td>5.355664e+06</td>\n      <td>1074.064784</td>\n      <td>0.189360</td>\n      <td>874.695920</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.109442</td>\n      <td>0.016079</td>\n      <td>-0.172291</td>\n      <td>6.682396e+06</td>\n      <td>-795.000000</td>\n      <td>0.183581</td>\n      <td>849.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.143482</td>\n      <td>0.046260</td>\n      <td>0.106536</td>\n      <td>1.310465e+07</td>\n      <td>492.250000</td>\n      <td>0.230175</td>\n      <td>1064.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.372455</td>\n      <td>0.049210</td>\n      <td>0.362540</td>\n      <td>1.900122e+07</td>\n      <td>1675.000000</td>\n      <td>0.449472</td>\n      <td>2076.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.516378</td>\n      <td>0.052960</td>\n      <td>0.519670</td>\n      <td>2.262042e+07</td>\n      <td>2400.750000</td>\n      <td>0.599429</td>\n      <td>2769.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.825197</td>\n      <td>0.110551</td>\n      <td>0.915283</td>\n      <td>3.173261e+07</td>\n      <td>4228.000000</td>\n      <td>0.918887</td>\n      <td>4245.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbnn_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:50.077054354Z",
     "start_time": "2023-06-23T15:11:50.015185143Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:50.077281073Z",
     "start_time": "2023-06-23T15:11:50.040692148Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:50.330121176Z",
     "start_time": "2023-06-23T15:11:50.220487528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "     model  pred_gpu      pred_std  true_norm_gpu      true_gpu  true_n_gpu  \\\n0  MCDLSTM  0.810325  2.384186e-07       0.804885  2.918980e+07        3718   \n1  MCDLSTM  0.798122  5.960465e-08       0.814360  2.940805e+07        3762   \n\n      ub_95  pred_n_gpu_95  \n0  0.810325           3744  \n1  0.798122           3687  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MCDLSTM</td>\n      <td>0.810325</td>\n      <td>2.384186e-07</td>\n      <td>0.804885</td>\n      <td>2.918980e+07</td>\n      <td>3718</td>\n      <td>0.810325</td>\n      <td>3744</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MCDLSTM</td>\n      <td>0.798122</td>\n      <td>5.960465e-08</td>\n      <td>0.814360</td>\n      <td>2.940805e+07</td>\n      <td>3762</td>\n      <td>0.798122</td>\n      <td>3687</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_results = pd.read_csv(\"output_MCDLSTM-ali20_g-gpu-w288-h2.csv\")\n",
    "monte_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "monte_results[\"true_gpu\"] = g_truth\n",
    "monte_results[\"model\"] = [\"MCDLSTM\" for i in range(len(monte_results))]\n",
    "monte_results.rename(columns={\"avggpu\": \"pred_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = monte_results.pop('model')\n",
    "monte_results.insert(0, 'model', first_column)\n",
    "monte_results[\"true_n_gpu\"] = monte_results.apply(lambda row: math.ceil(row[\"true_norm_gpu\"]/gpu_conv_value), axis=1)\n",
    "monte_results[\"ub_95\"] = monte_results.apply(lambda row: find_upper_bound(row[\"pred_gpu\"], row[\"pred_std\"], alpha=0.95), axis=1)\n",
    "monte_results[\"pred_n_gpu_95\"] = monte_results.apply(lambda row: math.ceil(row[\"ub_95\"]/gpu_conv_value), axis=1)\n",
    "monte_results.to_csv(\"scenarios/monte_results.csv\")\n",
    "monte_results.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:50.854717083Z",
     "start_time": "2023-06-23T15:11:50.480518212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "          pred_gpu      pred_std  true_norm_gpu      true_gpu   true_n_gpu  \\\ncount  2582.000000  2.582000e+03    2582.000000  2.582000e+03  2582.000000   \nmean      0.337572  6.597421e-08       0.328949  1.822752e+07  1519.997289   \nstd       0.214559  6.558250e-08       0.232520  5.355664e+06  1074.064784   \nmin      -0.039172  0.000000e+00      -0.172291  6.682396e+06  -795.000000   \n25%       0.125868  1.117587e-08       0.106536  1.310465e+07   492.250000   \n50%       0.367512  5.960465e-08       0.362540  1.900122e+07  1675.000000   \n75%       0.512203  8.940697e-08       0.519670  2.262042e+07  2400.750000   \nmax       0.893295  2.980232e-07       0.915283  3.173261e+07  4228.000000   \n\n             ub_95  pred_n_gpu_95  \ncount  2582.000000    2582.000000  \nmean      0.337572    1559.831913  \nstd       0.214559     991.103168  \nmin      -0.039172    -180.000000  \n25%       0.125868     581.500000  \n50%       0.367512    1698.000000  \n75%       0.512203    2366.500000  \nmax       0.893295    4127.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.337572</td>\n      <td>6.597421e-08</td>\n      <td>0.328949</td>\n      <td>1.822752e+07</td>\n      <td>1519.997289</td>\n      <td>0.337572</td>\n      <td>1559.831913</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.214559</td>\n      <td>6.558250e-08</td>\n      <td>0.232520</td>\n      <td>5.355664e+06</td>\n      <td>1074.064784</td>\n      <td>0.214559</td>\n      <td>991.103168</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.039172</td>\n      <td>0.000000e+00</td>\n      <td>-0.172291</td>\n      <td>6.682396e+06</td>\n      <td>-795.000000</td>\n      <td>-0.039172</td>\n      <td>-180.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.125868</td>\n      <td>1.117587e-08</td>\n      <td>0.106536</td>\n      <td>1.310465e+07</td>\n      <td>492.250000</td>\n      <td>0.125868</td>\n      <td>581.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.367512</td>\n      <td>5.960465e-08</td>\n      <td>0.362540</td>\n      <td>1.900122e+07</td>\n      <td>1675.000000</td>\n      <td>0.367512</td>\n      <td>1698.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.512203</td>\n      <td>8.940697e-08</td>\n      <td>0.519670</td>\n      <td>2.262042e+07</td>\n      <td>2400.750000</td>\n      <td>0.512203</td>\n      <td>2366.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.893295</td>\n      <td>2.980232e-07</td>\n      <td>0.915283</td>\n      <td>3.173261e+07</td>\n      <td>4228.000000</td>\n      <td>0.893295</td>\n      <td>4127.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:50.898809554Z",
     "start_time": "2023-06-23T15:11:50.854972130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:53.491017207Z",
     "start_time": "2023-06-23T15:11:53.463047804Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "   model  pred_gpu  pred_std  true_norm_gpu      true_gpu  true_n_gpu  \\\n0  FLBNN  0.614491  0.064371       0.804885  2.918980e+07        3718   \n1  FLBNN  0.614068  0.063943       0.814360  2.940805e+07        3762   \n\n      ub_95  pred_n_gpu_95  \n0  0.720371           3328  \n1  0.719245           3323  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FLBNN</td>\n      <td>0.614491</td>\n      <td>0.064371</td>\n      <td>0.804885</td>\n      <td>2.918980e+07</td>\n      <td>3718</td>\n      <td>0.720371</td>\n      <td>3328</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FLBNN</td>\n      <td>0.614068</td>\n      <td>0.063943</td>\n      <td>0.814360</td>\n      <td>2.940805e+07</td>\n      <td>3762</td>\n      <td>0.719245</td>\n      <td>3323</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flbnn_results = pd.read_csv(\"output_FLBNN-ali20_g-gpu-w288-h2.csv\")\n",
    "flbnn_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "flbnn_results[\"true_gpu\"] = g_truth\n",
    "flbnn_results[\"model\"] = [\"FLBNN\" for i in range(len(flbnn_results))]\n",
    "flbnn_results.rename(columns={\"avggpu\": \"pred_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = flbnn_results.pop('model')\n",
    "flbnn_results.insert(0, 'model', first_column)\n",
    "flbnn_results[\"true_n_gpu\"] = flbnn_results.apply(lambda row: math.ceil(row[\"true_norm_gpu\"]/gpu_conv_value), axis=1)\n",
    "flbnn_results[\"ub_95\"] = flbnn_results.apply(lambda row: find_upper_bound(row[\"pred_gpu\"], row[\"pred_std\"], alpha=0.95), axis=1)\n",
    "flbnn_results[\"pred_n_gpu_95\"] = flbnn_results.apply(lambda row: math.ceil(row[\"ub_95\"]/gpu_conv_value), axis=1)\n",
    "flbnn_results.to_csv(\"scenarios/flbnn_results.csv\")\n",
    "flbnn_results.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:54.044036077Z",
     "start_time": "2023-06-23T15:11:53.682381479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:54.044242857Z",
     "start_time": "2023-06-23T15:11:54.029459662Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "   model  pred_gpu  true_norm_gpu      true_gpu  true_n_gpu     ub_95  \\\n0  LSTMQ  0.867105       0.804885  2.918980e+07        3718  0.867105   \n1  LSTMQ  0.860391       0.814360  2.940805e+07        3762  0.860391   \n\n   pred_n_gpu_95  \n0           4006  \n1           3975  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_gpu</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LSTMQ</td>\n      <td>0.867105</td>\n      <td>0.804885</td>\n      <td>2.918980e+07</td>\n      <td>3718</td>\n      <td>0.867105</td>\n      <td>4006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LSTMQ</td>\n      <td>0.860391</td>\n      <td>0.814360</td>\n      <td>2.940805e+07</td>\n      <td>3762</td>\n      <td>0.860391</td>\n      <td>3975</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmq_results = pd.read_csv(\"output_LSTMQ-ali20_g-gpu-w288-h2.csv\")\n",
    "lstmq_results.drop(labels=[\"Unnamed: 0\", \"std\"], inplace=True, axis=1)\n",
    "lstmq_results[\"true_gpu\"] = g_truth\n",
    "lstmq_results[\"model\"] = [\"LSTMQ\" for i in range(len(lstmq_results))]\n",
    "lstmq_results.rename(columns={\"avggpu\": \"pred_gpu\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = lstmq_results.pop('model')\n",
    "lstmq_results.insert(0, 'model', first_column)\n",
    "lstmq_results[\"true_n_gpu\"] = lstmq_results.apply(lambda row: math.ceil(row[\"true_norm_gpu\"]/gpu_conv_value), axis=1)\n",
    "lstmq_results[\"ub_95\"] = lstmq_results[\"pred_gpu\"].values\n",
    "lstmq_results[\"pred_n_gpu_95\"] = lstmq_results.apply(lambda row: math.ceil(row[\"ub_95\"]/gpu_conv_value), axis=1)\n",
    "lstmq_results.to_csv(\"scenarios/lstmq_results.csv\")\n",
    "lstmq_results.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:54.162984273Z",
     "start_time": "2023-06-23T15:11:54.037458535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:54.962682947Z",
     "start_time": "2023-06-23T15:11:54.954676417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:55.221722912Z",
     "start_time": "2023-06-23T15:11:55.183540652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "  model  pred_gpu  true_norm_gpu      true_gpu  true_n_gpu     ub_95  \\\n0  LSTM  0.835576       0.804885  2.918980e+07        3718  0.877354   \n1  LSTM  0.822173       0.814360  2.940805e+07        3762  0.863281   \n\n   pred_n_gpu_95  \n0           4053  \n1           3988  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_gpu</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LSTM</td>\n      <td>0.835576</td>\n      <td>0.804885</td>\n      <td>2.918980e+07</td>\n      <td>3718</td>\n      <td>0.877354</td>\n      <td>4053</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LSTM</td>\n      <td>0.822173</td>\n      <td>0.814360</td>\n      <td>2.940805e+07</td>\n      <td>3762</td>\n      <td>0.863281</td>\n      <td>3988</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_upper_bound = 0.05\n",
    "lstm_results = pd.read_csv(\"output_LSTM-ali20_g-gpu-w288-h2.csv\")\n",
    "lstm_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "lstm_results[\"true_gpu\"] = g_truth\n",
    "lstm_results[\"model\"] = [\"LSTM\" for i in range(len(lstm_results))]\n",
    "lstm_results.rename(columns={\"avggpu\": \"pred_gpu\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = lstm_results.pop('model')\n",
    "lstm_results.insert(0, 'model', first_column)\n",
    "lstm_results[\"true_n_gpu\"] = lstm_results.apply(lambda row: math.ceil(row[\"true_norm_gpu\"]/gpu_conv_value), axis=1)\n",
    "lstm_results[\"ub_95\"] = lstm_results[\"pred_gpu\"].values\n",
    "lstm_results[\"ub_95\"] = [value+(perc_upper_bound*value) for value in lstm_results[\"ub_95\"].values]\n",
    "lstm_results[\"pred_n_gpu_95\"] = lstm_results.apply(lambda row: math.ceil(row[\"ub_95\"]/gpu_conv_value), axis=1)\n",
    "lstm_results.to_csv(\"scenarios/lstm_results.csv\")\n",
    "lstm_results.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:11:55.457913449Z",
     "start_time": "2023-06-23T15:11:55.364605272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:12.980478441Z",
     "start_time": "2023-06-23T08:08:12.901305453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:12.980625013Z",
     "start_time": "2023-06-23T08:08:12.905522482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:13.546315714Z",
     "start_time": "2023-06-23T08:08:13.422656753Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Accuracy</h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def print_results(df_results):\n",
    "\n",
    "    mse_value = mean_squared_error(df_results.pred_gpu, df_results.true_norm_gpu)\n",
    "    print(f\"MSE: {mse_value}\")\n",
    "\n",
    "    mae_value = mean_absolute_error(df_results.pred_gpu, df_results.true_norm_gpu)\n",
    "    print(\"MAE\", mae_value)\n",
    "\n",
    "    sr_value = sum(df_results.ub_95>df_results.true_norm_gpu)/df_results.shape[0]\n",
    "    print(\"SR\", sr_value)\n",
    "\n",
    "    # up_value = sum((df_results.ub_95<df_results.true_norm_gpu)*(df_results.true_norm_gpu-df_results.ub_95))/sum((df_results.ub_95<df_results.true_norm_gpu)*df_results.true_norm_gpu)\n",
    "    # up_value = sum((df_results.ub_95<df_results.true_norm_gpu)*(df_results.true_norm_gpu-df_results.ub_95))/sum(df_results.ub_95<df_results.true_norm_gpu)\n",
    "\n",
    "    up_value = sum((df_results.ub_95<df_results.true_norm_gpu)*((df_results.true_norm_gpu-df_results.ub_95)))/sum(df_results.true_norm_gpu)\n",
    "    print(\"UP\", up_value)\n",
    "\n",
    "    # op_value = sum((df_results.ub_95>df_results.true_norm_gpu)*(df_results.ub_95-df_results.true_norm_gpu))/sum((df_results.ub_95>df_results.true_norm_gpu)*df_results.true_norm_gpu)\n",
    "\n",
    "    # op_value = sum((df_results.ub_95>df_results.true_norm_gpu)*(df_results.ub_95-df_results.true_norm_gpu))/sum(df_results.ub_95>df_results.true_norm_gpu)\n",
    "\n",
    "    op_value = sum((df_results.ub_95>df_results.true_norm_gpu)*((df_results.ub_95-df_results.true_norm_gpu)))/sum(df_results.true_norm_gpu)\n",
    "    print(\"OP\", op_value)\n",
    "    return mse_value, mae_value, sr_value, up_value, op_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:13.908397260Z",
     "start_time": "2023-06-23T08:08:13.812640365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCDLSTM\n",
      "MSE: 0.002068030780908928\n",
      "MAE 0.03390599167512373\n",
      "SR 0.6107668474051123\n",
      "UP 0.03842959421563328\n",
      "OP 0.06464405041741941\n",
      "\n",
      "HBNN\n",
      "MSE: 0.005862803756676761\n",
      "MAE 0.05507856979953394\n",
      "SR 0.9686289697908598\n",
      "UP 0.0038730693286546914\n",
      "OP 0.3393694417527197\n",
      "\n",
      "FLBNN\n",
      "MSE: 0.009376300999237301\n",
      "MAE 0.0755649909627305\n",
      "SR 0.9523625096824168\n",
      "UP 0.008301780086253503\n",
      "OP 0.44098144561955077\n",
      "\n",
      "LSTMQ\n",
      "MSE: 0.006166121405354145\n",
      "MAE 0.06926118064031304\n",
      "SR 0.935708752904725\n",
      "UP 0.0059744431136667855\n",
      "OP 0.20457833957367744\n",
      "\n",
      "LSTM\n",
      "MSE: 0.0032931226669689773\n",
      "MAE 0.04235054682901876\n",
      "SR 0.8679318357862122\n",
      "UP 0.011700511268966924\n",
      "OP 0.149381862297774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\"MCDLSTM\": monte_results,\n",
    "          \"HBNN\": hbnn_results,\n",
    "          \"FLBNN\": flbnn_results,\n",
    "          \"LSTMQ\": lstmq_results,\n",
    "          \"LSTM\": lstm_results\n",
    "          }\n",
    "mse_values = []\n",
    "mae_values = []\n",
    "sr_values = []\n",
    "up_values = []\n",
    "op_values = []\n",
    "for model in models:\n",
    "    print(model)\n",
    "    a, b, c, d, e = print_results(models[model])\n",
    "    mse_values.append(a)\n",
    "    mae_values.append(b)\n",
    "    sr_values.append(c)\n",
    "    up_values.append(d)\n",
    "    op_values.append(e)\n",
    "    print()\n",
    "data = {\"model\": [\"MCDLSTM\", \"HBNN\", \"FLBNN\", \"LSTMQ\", \"LSTM\"],\n",
    "        \"MSE\": mse_values,\n",
    "        \"MAE\": mae_values,\n",
    "        \"SR\": sr_values,\n",
    "        \"UP\": up_values,\n",
    "        \"OP\": op_values\n",
    "        }\n",
    "df_accuracy = pd.DataFrame(data=data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:14.044868538Z",
     "start_time": "2023-06-23T08:08:14.016348037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "     model       MSE       MAE        SR        UP        OP\n0  MCDLSTM  0.002068  0.033906  0.610767  0.038430  0.064644\n1     HBNN  0.005863  0.055079  0.968629  0.003873  0.339369\n2    FLBNN  0.009376  0.075565  0.952363  0.008302  0.440981\n3    LSTMQ  0.006166  0.069261  0.935709  0.005974  0.204578\n4     LSTM  0.003293  0.042351  0.867932  0.011701  0.149382",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>MSE</th>\n      <th>MAE</th>\n      <th>SR</th>\n      <th>UP</th>\n      <th>OP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MCDLSTM</td>\n      <td>0.002068</td>\n      <td>0.033906</td>\n      <td>0.610767</td>\n      <td>0.038430</td>\n      <td>0.064644</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HBNN</td>\n      <td>0.005863</td>\n      <td>0.055079</td>\n      <td>0.968629</td>\n      <td>0.003873</td>\n      <td>0.339369</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FLBNN</td>\n      <td>0.009376</td>\n      <td>0.075565</td>\n      <td>0.952363</td>\n      <td>0.008302</td>\n      <td>0.440981</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LSTMQ</td>\n      <td>0.006166</td>\n      <td>0.069261</td>\n      <td>0.935709</td>\n      <td>0.005974</td>\n      <td>0.204578</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LSTM</td>\n      <td>0.003293</td>\n      <td>0.042351</td>\n      <td>0.867932</td>\n      <td>0.011701</td>\n      <td>0.149382</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:14.228827628Z",
     "start_time": "2023-06-23T08:08:14.180955627Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_accuracy.to_csv(\"accuracy_table.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:14.444082946Z",
     "start_time": "2023-06-23T08:08:14.424425465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Baselines</h2>\n",
    "\n",
    "a. Running exactly the required number of GPUs that would be specified by our schedulers acting as an oracle. Will have minimal energy use, and a 100% success rate.\n",
    "\n",
    "b. Always running the maximum number of GPUs acting as a dummy predictor. Will have maximal energy use, and a 100% success rate.\n",
    "\n",
    "c. Always running the GPUs that were specified by the oracle for the previous time window."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# define the costs (expressed in Watt)\n",
    "cost_on_5_mins = 230\n",
    "turn_on_cost = 0.25*cost_on_5_mins\n",
    "\n",
    "n_total_gpus = 6742 # total number of GPUs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:09.410291208Z",
     "start_time": "2023-06-23T08:15:09.400235432Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Energy scenario 1</h2>\n",
    "\n",
    "All GPU machines have the same computational power and they consume the same amount of energy.\n",
    "\n",
    "The scenario has no memory (no GPU state transitions), i.e. the energy consumption is calculated independently from the previous GPUs states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "energy_baseline_a = hbnn_results[\"true_n_gpu\"].values.sum()\n",
    "energy_baseline_b = n_total_gpus*len(hbnn_results)\n",
    "baseline_c_values = list(hbnn_results[\"true_n_gpu\"].values[:-1])\n",
    "baseline_c_values.insert(baseline_c_values[0], 0) # because I do not know the first value\n",
    "energy_baseline_c = np.sum(baseline_c_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:09.721067828Z",
     "start_time": "2023-06-23T08:15:09.711210153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "scenario_1_costs = {\"baseline_a\": energy_baseline_a,\n",
    "                \"baseline_b\": energy_baseline_b,\n",
    "                \"baseline_c\": energy_baseline_c,\n",
    "                \"HBNN\": hbnn_results[\"pred_n_gpu_95\"].values.sum(),\n",
    "                \"MCD\": monte_results[\"pred_n_gpu_95\"].values.sum(),\n",
    "                \"HBNN++\": flbnn_results[\"pred_n_gpu_95\"].values.sum(),\n",
    "                \"LSTMQ\": lstmq_results[\"pred_n_gpu_95\"].values.sum(),\n",
    "                \"LSTM\": lstm_results[\"pred_n_gpu_95\"].values.sum(),\n",
    "                }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:09.892764952Z",
     "start_time": "2023-06-23T08:15:09.887676420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "        model  % energy savings\n0  baseline_a             77.45\n1  baseline_b              0.00\n2  baseline_c             77.45\n3        HBNN             69.89\n4         MCD             76.86\n5      HBNN++             67.70\n6       LSTMQ             72.98\n7        LSTM             74.35",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>% energy savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>baseline_a</td>\n      <td>77.45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>baseline_b</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>baseline_c</td>\n      <td>77.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HBNN</td>\n      <td>69.89</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MCD</td>\n      <td>76.86</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HBNN++</td>\n      <td>67.70</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LSTMQ</td>\n      <td>72.98</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LSTM</td>\n      <td>74.35</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_column = [model for model in scenario_1_costs]\n",
    "energy_value = [100 - round(scenario_1_costs[model]/scenario_1_costs[\"baseline_b\"]*100, 2) for model in scenario_1_costs]\n",
    "d = {\"model\": model_column, \"% energy savings\": energy_value}\n",
    "df_scenario_1 = pd.DataFrame(data=d)\n",
    "df_scenario_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:10.125770809Z",
     "start_time": "2023-06-23T08:15:10.090762669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:10.327812874Z",
     "start_time": "2023-06-23T08:15:10.299784666Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:10.458276748Z",
     "start_time": "2023-06-23T08:15:10.444642555Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Energy scenario 3</h2>\n",
    "\n",
    "All GPU machines have the same computational power and they consume the same amount of energy when ON.\n",
    "We model also the state of a GPU {ON, OFF}, and there is a fixed cost on transitioning from OFF to ON. No cost from ON to OFF.\n",
    "\n",
    "Initial scenario: All GPUs needed are ON, and there is no associated cost for this. Then, GPUs are switched ON and OFF based on the predicted workload. The energy consumtpion is calculated accordingly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def calculate_consumption(n_gpu_predicted, history, fixed_cost_run, fixed_cost_switch):\n",
    "    if n_gpu_predicted > history:\n",
    "        transition_cost = (n_gpu_predicted - history)*fixed_cost_switch\n",
    "    else:\n",
    "        transition_cost = 0\n",
    "    return transition_cost + n_gpu_predicted*fixed_cost_run"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:11.794638957Z",
     "start_time": "2023-06-23T08:15:11.785544141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "scenario_3_costs = {}\n",
    "models = {\"MCD\": monte_results,\n",
    "          \"HBNN\": hbnn_results,\n",
    "          \"HBNN++\": flbnn_results,\n",
    "          \"LSTMQ\": lstmq_results,\n",
    "          \"LSTM\": lstm_results\n",
    "          }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:11.991824648Z",
     "start_time": "2023-06-23T08:15:11.981558803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "total_cost = 0\n",
    "gpu_history = hbnn_results[\"true_n_gpu\"].values\n",
    "for i, n_gpu in enumerate(gpu_history):\n",
    "    if i == 0:\n",
    "        total_cost += n_gpu\n",
    "        continue\n",
    "    total_cost += calculate_consumption(n_gpu, gpu_history[i-1], cost_on_5_mins, turn_on_cost)\n",
    "scenario_3_costs[\"baseline_a\"] = total_cost\n",
    "scenario_3_costs[\"baseline_b\"] = n_total_gpus*len(hbnn_results)*cost_on_5_mins + turn_on_cost*n_total_gpus"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:12.246202941Z",
     "start_time": "2023-06-23T08:15:12.203239231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# TODO baseline c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:12.388870636Z",
     "start_time": "2023-06-23T08:15:12.382909579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    total_cost = 0\n",
    "    gpu_history = models[model][\"pred_n_gpu_95\"].values\n",
    "    for i, n_gpu in enumerate(gpu_history):\n",
    "        if i == 0:\n",
    "            total_cost += n_gpu*cost_on_5_mins\n",
    "            continue\n",
    "        total_cost += calculate_consumption(n_gpu, gpu_history[i-1], cost_on_5_mins, turn_on_cost)\n",
    "    scenario_3_costs[model] = total_cost"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:12.632654685Z",
     "start_time": "2023-06-23T08:15:12.574190194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "        model  % energy savings\n0  baseline_a             77.36\n1  baseline_b              0.00\n2         MCD             76.75\n3        HBNN             69.82\n4      HBNN++             67.67\n5       LSTMQ             72.86\n6        LSTM             74.23",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>% energy savings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>baseline_a</td>\n      <td>77.36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>baseline_b</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MCD</td>\n      <td>76.75</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HBNN</td>\n      <td>69.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HBNN++</td>\n      <td>67.67</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LSTMQ</td>\n      <td>72.86</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LSTM</td>\n      <td>74.23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_column = [model for model in scenario_3_costs]\n",
    "energy_value = [100 - round(scenario_3_costs[model]/scenario_3_costs[\"baseline_b\"]*100, 2) for model in scenario_3_costs]\n",
    "d = {\"model\": model_column, \"% energy savings\": energy_value}\n",
    "df_scenario_3 = pd.DataFrame(data=d)\n",
    "df_scenario_3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:15:13.429471098Z",
     "start_time": "2023-06-23T08:15:13.421376190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T08:08:31.321642735Z",
     "start_time": "2023-06-23T08:08:31.314222886Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Energy scenario 2</h2>\n",
    "\n",
    "All GPUs are of different characteristics. At the beginning of each time window, all GPUs are OFF."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def allocate_resources(w_demand: float,\n",
    "                       df_stat: pd.DataFrame\n",
    "                       ) -> float:\n",
    "    df_allocation = df_stat.copy()\n",
    "    wd_rem = w_demand\n",
    "    cost = 0\n",
    "    while wd_rem > 0:\n",
    "        # if a single GPU can satisfy the remaining work, we choose the cheapest one.\n",
    "        if wd_rem < max(df_allocation.w):\n",
    "            df_allocation = df_allocation[df_allocation[\"w\"] > wd_rem]\n",
    "            df_allocation.sort_values(by='cost', inplace=True)\n",
    "            cost += df_allocation.cost.head(1).values[0]\n",
    "            break\n",
    "\n",
    "        # Otherwise we select the most efficient\n",
    "        wd_rem -= df_allocation.w.tail(1).values[0]\n",
    "        cost += df_allocation.cost.tail(1).values[0]\n",
    "        # remove the GPU used\n",
    "        df_allocation.drop(df_allocation.tail(1).index,inplace=True) # drop last n rows\n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T14:47:33.652255742Z",
     "start_time": "2023-06-23T14:47:33.624350383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gpu_name         w       e         c  s      cost       eff\n",
      "3370     V100  0.000283  0.0233  0.005825  1  0.029125  0.009724\n",
      "2868     V100  0.000283  0.0233  0.005825  1  0.029125  0.009724\n"
     ]
    }
   ],
   "source": [
    "gpus_specs = {\"P100\": (1596, 0.000404575892857, 0.0208),\n",
    "              \"T4\": (994, 0.00056640625, 0.0058),\n",
    "              \"V100\": (1912, 0.000283203125, 0.0233),\n",
    "              \"MISC\": (2240, 0.000361596009975, 0.0208),\n",
    "              }\n",
    "\n",
    "# build dataframe of GPUs\n",
    "w = [] # stores workload that GPUs can provide\n",
    "e = [] # stores energy consumption\n",
    "c = [] # stores energy cost to turn on GPUs\n",
    "s = [] # stores the status of GPUs\n",
    "g_name = [] # stores the name of the GPUs\n",
    "for gpu_name in gpus_specs:\n",
    "    w_value = gpus_specs[gpu_name][1]\n",
    "    n_g = gpus_specs[gpu_name][0]\n",
    "    e_g = gpus_specs[gpu_name][2]\n",
    "    c_g = gpus_specs[gpu_name][2]*0.25\n",
    "    g_name.extend([gpu_name for i in range(n_g)])\n",
    "    w.extend([w_value for i in range(n_g)])\n",
    "    e.extend([e_g for i in range(n_g)])\n",
    "    c.extend([c_g for i in range(n_g)])\n",
    "    s.extend([1 for i in range(n_g)])\n",
    "\n",
    "d = {\"gpu_name\": g_name, 'w': w, 'e': e, 'c': c, 's': s}\n",
    "df_gpus_status = pd.DataFrame(data=d)\n",
    "\n",
    "# efficiency of GPU = workload provided / energy required\n",
    "df_gpus_status['cost'] = df_gpus_status.e + df_gpus_status.s * df_gpus_status.c\n",
    "df_gpus_status['eff'] = df_gpus_status.w/ df_gpus_status.cost\n",
    "\n",
    "df_gpus_status = df_gpus_status.sort_values(by='eff')\n",
    "print(df_gpus_status.head(2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:26:19.148103740Z",
     "start_time": "2023-06-23T15:26:19.135854217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-23 17:26:25.239993 -- BEGIN!\n",
      "2023-06-23 17:27:57.800369 -- Done with model baseline_a!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_136730/764227734.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpred_workloads\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mdemands\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpred_workloads\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mtot_costs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mallocate_resources\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdemand\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf_gpus_status\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdemand\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdemands\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m     \u001B[0mscenario_2_costs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtot_costs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{datetime.datetime.now()} -- Done with model {model}!\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_136730/764227734.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpred_workloads\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mdemands\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpred_workloads\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mtot_costs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mallocate_resources\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdemand\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf_gpus_status\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdemand\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdemands\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m     \u001B[0mscenario_2_costs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtot_costs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{datetime.datetime.now()} -- Done with model {model}!\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_136730/3336247459.py\u001B[0m in \u001B[0;36mallocate_resources\u001B[0;34m(w_demand, df_stat)\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mwd_rem\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;31m# if a single GPU can satisfy the remaining work, we choose the cheapest one.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mwd_rem\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_allocation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m             \u001B[0mdf_allocation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_allocation\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdf_allocation\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"w\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mwd_rem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m             \u001B[0mdf_allocation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mby\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cost'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# pred_workloads = {\"baseline_a\": list(hbnn_results[\"true_norm_gpu\"].values),\n",
    "#                   \"HBNN\": list(hbnn_results[\"ub_95\"].values),\n",
    "#                   }\n",
    "\n",
    "pred_workloads = {\"baseline_a\": hbnn_results[\"true_norm_gpu\"].values[:50],\n",
    "                  \"baseline_b\": [1.45 for i in range(len(hbnn_results))], # max possible workload\n",
    "                  \"HBNN\": hbnn_results[\"ub_95\"].values[:50],\n",
    "                  \"MCD\": monte_results[\"ub_95\"].values[:50],\n",
    "                  \"HBNN++\": flbnn_results[\"ub_95\"].values[:50],\n",
    "                  \"LSTMQ\": lstmq_results[\"ub_95\"].values[:50],\n",
    "                  \"LSTM\": lstm_results[\"ub_95\"].values[:50],\n",
    "                  }\n",
    "print(f\"{datetime.datetime.now()} -- BEGIN!\")\n",
    "scenario_2_costs = {}\n",
    "for model in pred_workloads:\n",
    "    demands = pred_workloads[model]\n",
    "    tot_costs = [allocate_resources(demand, df_gpus_status) for demand in demands]\n",
    "    scenario_2_costs[model] = np.sum(tot_costs)\n",
    "    print(f\"{datetime.datetime.now()} -- Done with model {model}!\")\n",
    "print(f\"{datetime.datetime.now()} -- END!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:29:09.599915862Z",
     "start_time": "2023-06-23T15:26:25.243337813Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_column = [model for model in scenario_2_costs]\n",
    "energy_value = [100 - round(scenario_2_costs[model]/scenario_2_costs[\"baseline_b\"]*100, 2) for model in scenario_2_costs]\n",
    "d = {\"model\": model_column, \"% energy savings\": energy_value}\n",
    "scenario_2_costs = pd.DataFrame(data=d)\n",
    "scenario_2_costs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "{'baseline_a': 2317.0266000000797}"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_2_costs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T15:04:20.533320760Z",
     "start_time": "2023-06-23T15:04:20.523907828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "  model  pred_gpu  pred_std  true_norm_gpu      true_gpu  true_n_gpu    ub_95  \\\n0  HBNN   0.79237  0.058169       0.804885  2.918980e+07        3718  0.88805   \n\n   pred_n_gpu_95  \n0           4103  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_95</th>\n      <th>pred_n_gpu_95</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HBNN</td>\n      <td>0.79237</td>\n      <td>0.058169</td>\n      <td>0.804885</td>\n      <td>2.918980e+07</td>\n      <td>3718</td>\n      <td>0.88805</td>\n      <td>4103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbnn_results.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T14:16:59.035643946Z",
     "start_time": "2023-06-23T14:16:58.992342831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
