{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:37.412591304Z",
     "start_time": "2023-06-29T08:09:36.539420508Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def find_upper_bound(mu, std, alpha=0.95):\n",
    "    z_value = norm.ppf(alpha)\n",
    "    return mu + std * z_value\n",
    "\n",
    "def find_optimal_std_lstm(train, confidence, train_win):\n",
    "    \"\"\"\n",
    "    conf_levels = list of confidence level e.g. np.arange(0.90, 1, 0.01) from which you want to find the optimal std\n",
    "    train_win: int, lenght of the past history used for finding the optimal standard deviation\n",
    "    \"\"\"\n",
    "    stds_test = np.arange(0.01, 1., 0.0005) # this range needs to be set for ali2020\n",
    "    train_d = None\n",
    "    if train_win:\n",
    "        train_d = train.iloc[-train_win:].copy()\n",
    "    for std in stds_test:\n",
    "        train_d[\"up\"] = train_d.apply(lambda row: find_upper_bound(row[\"avggpu\"], std, confidence), axis=1)\n",
    "        # count how much you under predict\n",
    "        up = sum(train_d.up < train_d.labels)/len(train_d)*100\n",
    "        count_perc = 100. - up\n",
    "        if count_perc >= confidence:\n",
    "            return std\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:37.502286986Z",
     "start_time": "2023-06-29T08:09:37.325295200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "gpu_conv_value = 0.00021648585046\n",
    "gpu_no_norm_conv_value = 6958.933333333333333\n",
    "per_unit_energy_cons = 1\n",
    "target_qos = [\"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:37.503286132Z",
     "start_time": "2023-06-29T08:09:37.331087183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         Unnamed: 0          time        avggpu     avggpumem\ncount  14358.000000  1.435800e+04  1.435800e+04  1.435800e+04\nmean    8928.500000  1.596240e+09  2.062431e+07  3.858848e+06\nstd     4144.941918  1.243483e+06  4.407054e+06  9.409406e+05\nmin     1750.000000  1.594087e+09  6.682396e+06  1.223004e+06\n25%     5339.250000  1.595163e+09  1.780858e+07  3.268815e+06\n50%     8928.500000  1.596240e+09  2.088287e+07  3.882400e+06\n75%    12517.750000  1.597317e+09  2.357788e+07  4.509566e+06\nmax    16107.000000  1.598394e+09  3.368392e+07  6.902691e+06",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>time</th>\n      <th>avggpu</th>\n      <th>avggpumem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14358.000000</td>\n      <td>1.435800e+04</td>\n      <td>1.435800e+04</td>\n      <td>1.435800e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8928.500000</td>\n      <td>1.596240e+09</td>\n      <td>2.062431e+07</td>\n      <td>3.858848e+06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4144.941918</td>\n      <td>1.243483e+06</td>\n      <td>4.407054e+06</td>\n      <td>9.409406e+05</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1750.000000</td>\n      <td>1.594087e+09</td>\n      <td>6.682396e+06</td>\n      <td>1.223004e+06</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5339.250000</td>\n      <td>1.595163e+09</td>\n      <td>1.780858e+07</td>\n      <td>3.268815e+06</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8928.500000</td>\n      <td>1.596240e+09</td>\n      <td>2.088287e+07</td>\n      <td>3.882400e+06</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>12517.750000</td>\n      <td>1.597317e+09</td>\n      <td>2.357788e+07</td>\n      <td>4.509566e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16107.000000</td>\n      <td>1.598394e+09</td>\n      <td>3.368392e+07</td>\n      <td>6.902691e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset = pd.read_csv(\"../saved_data/ali20/ali20_g.csv\")\n",
    "scaler = MinMaxScaler()\n",
    "factor=0.8\n",
    "scaler.fit(original_dataset.avggpu.iloc[:int(original_dataset.shape[0]*factor)].values.reshape(-1,1))\n",
    "original_dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:37.507232278Z",
     "start_time": "2023-06-29T08:09:37.343077096Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       pred_norm_gpu     pred_std  true_norm_gpu      true_gpu   true_n_gpu  \\\ncount    2582.000000  2582.000000    2582.000000  2.582000e+03  2582.000000   \nmean        0.357420     0.049786       0.328949  1.772129e+07  2547.051123   \nstd         0.187234     0.007063       0.232520  4.997830e+06   718.189507   \nmin         0.109442     0.016079      -0.172291  6.947540e+06   999.000000   \n25%         0.143482     0.046260       0.106536  1.294070e+07  1860.000000   \n50%         0.372455     0.049210       0.362540  1.844329e+07  2651.000000   \n75%         0.516378     0.052960       0.519670  2.182068e+07  3136.000000   \nmax         0.825197     0.110551       0.915283  3.032405e+07  4358.000000   \n\n           pred_gpu   ub_90_norm         ub_90  pred_n_gpu_90   ub_91_norm  \\\ncount  2.582000e+03  2582.000000  2.582000e+03    2582.000000  2582.000000   \nmean   1.833324e+07     0.421223  1.970464e+07    2832.052672     0.424171   \nstd    4.024433e+06     0.188831  4.058763e+06     583.245436     0.188915   \nmin    1.300316e+07     0.167206  1.424474e+07    2047.000000     0.169874   \n25%    1.373481e+07     0.210610  1.517768e+07    2181.500000     0.213763   \n50%    1.865642e+07     0.433462  1.996770e+07    2869.500000     0.436478   \n75%    2.174992e+07     0.581171  2.314260e+07    3325.750000     0.584130   \nmax    2.838773e+07     0.898194  2.995674e+07    4305.000000     0.901566   \n\n       ...  pred_n_gpu_96   ub_97_norm         ub_97  pred_n_gpu_97  \\\ncount  ...    2582.000000  2582.000000  2.582000e+03    2582.000000   \nmean   ...    2904.207204     0.451057  2.034590e+07    2924.202556   \nstd    ...     585.367004     0.189721  4.077902e+06     586.005779   \nmin    ...    2113.000000     0.194216  1.482530e+07    2131.000000   \n25%    ...    2260.000000     0.242669  1.586675e+07    2280.500000   \n50%    ...    2933.000000     0.460769  2.055465e+07    2954.500000   \n75%    ...    3398.000000     0.611112  2.378614e+07    3419.000000   \nmax    ...    4388.000000     0.932327  3.069040e+07    4411.000000   \n\n        ub_98_norm         ub_98  pred_n_gpu_98   ub_99_norm         ub_99  \\\ncount  2582.000000  2.582000e+03    2582.000000  2582.000000  2.582000e+03   \nmean      0.459668  2.053098e+07    2950.803641     0.473239  2.082269e+07   \nstd       0.189995  4.083786e+06     586.841574     0.190441  4.093385e+06   \nmin       0.202011  1.499286e+07    2155.000000     0.214298  1.525696e+07   \n25%       0.251706  1.606100e+07    2308.250000     0.265869  1.636542e+07   \n50%       0.468404  2.071875e+07    2977.500000     0.481697  2.100448e+07   \n75%       0.619926  2.397560e+07    3445.750000     0.633787  2.427352e+07   \nmax       0.942178  3.090215e+07    4441.000000     0.957705  3.123589e+07   \n\n       pred_n_gpu_99  \ncount    2582.000000  \nmean     2992.729280  \nstd       588.223474  \nmin      2193.000000  \n25%      2352.000000  \n50%      3019.000000  \n75%      3488.500000  \nmax      4489.000000  \n\n[8 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_norm_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>pred_gpu</th>\n      <th>ub_90_norm</th>\n      <th>ub_90</th>\n      <th>pred_n_gpu_90</th>\n      <th>ub_91_norm</th>\n      <th>...</th>\n      <th>pred_n_gpu_96</th>\n      <th>ub_97_norm</th>\n      <th>ub_97</th>\n      <th>pred_n_gpu_97</th>\n      <th>ub_98_norm</th>\n      <th>ub_98</th>\n      <th>pred_n_gpu_98</th>\n      <th>ub_99_norm</th>\n      <th>ub_99</th>\n      <th>pred_n_gpu_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>...</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.357420</td>\n      <td>0.049786</td>\n      <td>0.328949</td>\n      <td>1.772129e+07</td>\n      <td>2547.051123</td>\n      <td>1.833324e+07</td>\n      <td>0.421223</td>\n      <td>1.970464e+07</td>\n      <td>2832.052672</td>\n      <td>0.424171</td>\n      <td>...</td>\n      <td>2904.207204</td>\n      <td>0.451057</td>\n      <td>2.034590e+07</td>\n      <td>2924.202556</td>\n      <td>0.459668</td>\n      <td>2.053098e+07</td>\n      <td>2950.803641</td>\n      <td>0.473239</td>\n      <td>2.082269e+07</td>\n      <td>2992.729280</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.187234</td>\n      <td>0.007063</td>\n      <td>0.232520</td>\n      <td>4.997830e+06</td>\n      <td>718.189507</td>\n      <td>4.024433e+06</td>\n      <td>0.188831</td>\n      <td>4.058763e+06</td>\n      <td>583.245436</td>\n      <td>0.188915</td>\n      <td>...</td>\n      <td>585.367004</td>\n      <td>0.189721</td>\n      <td>4.077902e+06</td>\n      <td>586.005779</td>\n      <td>0.189995</td>\n      <td>4.083786e+06</td>\n      <td>586.841574</td>\n      <td>0.190441</td>\n      <td>4.093385e+06</td>\n      <td>588.223474</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.109442</td>\n      <td>0.016079</td>\n      <td>-0.172291</td>\n      <td>6.947540e+06</td>\n      <td>999.000000</td>\n      <td>1.300316e+07</td>\n      <td>0.167206</td>\n      <td>1.424474e+07</td>\n      <td>2047.000000</td>\n      <td>0.169874</td>\n      <td>...</td>\n      <td>2113.000000</td>\n      <td>0.194216</td>\n      <td>1.482530e+07</td>\n      <td>2131.000000</td>\n      <td>0.202011</td>\n      <td>1.499286e+07</td>\n      <td>2155.000000</td>\n      <td>0.214298</td>\n      <td>1.525696e+07</td>\n      <td>2193.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.143482</td>\n      <td>0.046260</td>\n      <td>0.106536</td>\n      <td>1.294070e+07</td>\n      <td>1860.000000</td>\n      <td>1.373481e+07</td>\n      <td>0.210610</td>\n      <td>1.517768e+07</td>\n      <td>2181.500000</td>\n      <td>0.213763</td>\n      <td>...</td>\n      <td>2260.000000</td>\n      <td>0.242669</td>\n      <td>1.586675e+07</td>\n      <td>2280.500000</td>\n      <td>0.251706</td>\n      <td>1.606100e+07</td>\n      <td>2308.250000</td>\n      <td>0.265869</td>\n      <td>1.636542e+07</td>\n      <td>2352.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.372455</td>\n      <td>0.049210</td>\n      <td>0.362540</td>\n      <td>1.844329e+07</td>\n      <td>2651.000000</td>\n      <td>1.865642e+07</td>\n      <td>0.433462</td>\n      <td>1.996770e+07</td>\n      <td>2869.500000</td>\n      <td>0.436478</td>\n      <td>...</td>\n      <td>2933.000000</td>\n      <td>0.460769</td>\n      <td>2.055465e+07</td>\n      <td>2954.500000</td>\n      <td>0.468404</td>\n      <td>2.071875e+07</td>\n      <td>2977.500000</td>\n      <td>0.481697</td>\n      <td>2.100448e+07</td>\n      <td>3019.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.516378</td>\n      <td>0.052960</td>\n      <td>0.519670</td>\n      <td>2.182068e+07</td>\n      <td>3136.000000</td>\n      <td>2.174992e+07</td>\n      <td>0.581171</td>\n      <td>2.314260e+07</td>\n      <td>3325.750000</td>\n      <td>0.584130</td>\n      <td>...</td>\n      <td>3398.000000</td>\n      <td>0.611112</td>\n      <td>2.378614e+07</td>\n      <td>3419.000000</td>\n      <td>0.619926</td>\n      <td>2.397560e+07</td>\n      <td>3445.750000</td>\n      <td>0.633787</td>\n      <td>2.427352e+07</td>\n      <td>3488.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.825197</td>\n      <td>0.110551</td>\n      <td>0.915283</td>\n      <td>3.032405e+07</td>\n      <td>4358.000000</td>\n      <td>2.838773e+07</td>\n      <td>0.898194</td>\n      <td>2.995674e+07</td>\n      <td>4305.000000</td>\n      <td>0.901566</td>\n      <td>...</td>\n      <td>4388.000000</td>\n      <td>0.932327</td>\n      <td>3.069040e+07</td>\n      <td>4411.000000</td>\n      <td>0.942178</td>\n      <td>3.090215e+07</td>\n      <td>4441.000000</td>\n      <td>0.957705</td>\n      <td>3.123589e+07</td>\n      <td>4489.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbnn_results = pd.read_csv(\"output_HBNN-ali20_g-gpu-w288-h2.csv\")\n",
    "hbnn_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "hbnn_results[\"model\"] = [\"HBNN\" for i in range(len(hbnn_results))]\n",
    "hbnn_results.rename(columns={\"avggpu\": \"pred_norm_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = hbnn_results.pop('model')\n",
    "hbnn_results.insert(0, 'model', first_column)\n",
    "hbnn_results[\"true_gpu\"] = scaler.inverse_transform(hbnn_results[\"true_norm_gpu\"].values.reshape(-1,1))\n",
    "hbnn_results[\"true_n_gpu\"] = hbnn_results.apply(lambda row: math.ceil(row[\"true_gpu\"]/gpu_no_norm_conv_value), axis=1)\n",
    "hbnn_results[\"pred_gpu\"] = scaler.inverse_transform(hbnn_results[\"pred_norm_gpu\"].values.reshape(-1,1))\n",
    "for target in target_qos:\n",
    "    alpa = float(int(target)/100)\n",
    "    hbnn_results[f\"ub_{target}_norm\"] = hbnn_results.apply(lambda row: find_upper_bound(row[\"pred_norm_gpu\"], row[\"pred_std\"], alpha=alpa), axis=1)\n",
    "    hbnn_results[f\"ub_{target}\"] = scaler.inverse_transform(hbnn_results[f\"ub_{target}_norm\"].values.reshape(-1,1))\n",
    "    hbnn_results[f\"pred_n_gpu_{target}\"] = hbnn_results.apply(lambda row: math.ceil(row[f\"ub_{target}\"]/gpu_no_norm_conv_value), axis=1)\n",
    "hbnn_results.to_csv(\"scenarios/hbnn_results.csv\")\n",
    "hbnn_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:41.464550885Z",
     "start_time": "2023-06-29T08:09:37.402184566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6904956366897531"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hbnn_results[\"true_gpu\"].values)/43916358.2147171"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:41.473517187Z",
     "start_time": "2023-06-29T08:09:41.467092247Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:41.478856828Z",
     "start_time": "2023-06-29T08:09:41.471978971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       pred_norm_gpu      pred_std  true_norm_gpu      true_gpu   true_n_gpu  \\\ncount    2582.000000  2.582000e+03    2582.000000  2.582000e+03  2582.000000   \nmean        0.337572  6.597421e-08       0.328949  1.772129e+07  2547.051123   \nstd         0.214559  6.558250e-08       0.232520  4.997830e+06   718.189507   \nmin        -0.039172  0.000000e+00      -0.172291  6.947540e+06   999.000000   \n25%         0.125868  1.117587e-08       0.106536  1.294070e+07  1860.000000   \n50%         0.367512  5.960465e-08       0.362540  1.844329e+07  2651.000000   \n75%         0.512203  8.940697e-08       0.519670  2.182068e+07  3136.000000   \nmax         0.893295  2.980232e-07       0.915283  3.032405e+07  4358.000000   \n\n           pred_gpu   ub_90_norm         ub_90  pred_n_gpu_90   ub_91_norm  \\\ncount  2.582000e+03  2582.000000  2.582000e+03    2582.000000  2582.000000   \nmean   1.790663e+07     0.337572  1.790664e+07    2573.692874     0.337572   \nstd    4.611775e+06     0.214559  4.611776e+06     662.714245     0.214559   \nmin    9.808823e+06    -0.039172  9.808824e+06    1410.000000    -0.039172   \n25%    1.335623e+07     0.125868  1.335623e+07    1919.500000     0.125868   \n50%    1.855016e+07     0.367512  1.855016e+07    2666.000000     0.367512   \n75%    2.166017e+07     0.512203  2.166018e+07    3112.750000     0.512203   \nmax    2.985144e+07     0.893295  2.985145e+07    4290.000000     0.893295   \n\n       ...  pred_n_gpu_96   ub_97_norm         ub_97  pred_n_gpu_97  \\\ncount  ...    2582.000000  2582.000000  2.582000e+03    2582.000000   \nmean   ...    2573.692874     0.337572  1.790664e+07    2573.692874   \nstd    ...     662.714245     0.214559  4.611777e+06     662.714245   \nmin    ...    1410.000000    -0.039172  9.808824e+06    1410.000000   \n25%    ...    1919.500000     0.125868  1.335623e+07    1919.500000   \n50%    ...    2666.000000     0.367512  1.855016e+07    2666.000000   \n75%    ...    3112.750000     0.512203  2.166018e+07    3112.750000   \nmax    ...    4290.000000     0.893295  2.985145e+07    4290.000000   \n\n        ub_98_norm         ub_98  pred_n_gpu_98   ub_99_norm         ub_99  \\\ncount  2582.000000  2.582000e+03    2582.000000  2582.000000  2.582000e+03   \nmean      0.337573  1.790664e+07    2573.693261     0.337573  1.790664e+07   \nstd       0.214559  4.611777e+06     662.713676     0.214559  4.611777e+06   \nmin      -0.039172  9.808824e+06    1410.000000    -0.039172  9.808824e+06   \n25%       0.125868  1.335623e+07    1919.500000     0.125868  1.335623e+07   \n50%       0.367512  1.855016e+07    2666.000000     0.367512  1.855016e+07   \n75%       0.512203  2.166018e+07    3112.750000     0.512203  2.166018e+07   \nmax       0.893295  2.985145e+07    4290.000000     0.893295  2.985145e+07   \n\n       pred_n_gpu_99  \ncount    2582.000000  \nmean     2573.693261  \nstd       662.713676  \nmin      1410.000000  \n25%      1919.500000  \n50%      2666.000000  \n75%      3112.750000  \nmax      4290.000000  \n\n[8 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_norm_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>pred_gpu</th>\n      <th>ub_90_norm</th>\n      <th>ub_90</th>\n      <th>pred_n_gpu_90</th>\n      <th>ub_91_norm</th>\n      <th>...</th>\n      <th>pred_n_gpu_96</th>\n      <th>ub_97_norm</th>\n      <th>ub_97</th>\n      <th>pred_n_gpu_97</th>\n      <th>ub_98_norm</th>\n      <th>ub_98</th>\n      <th>pred_n_gpu_98</th>\n      <th>ub_99_norm</th>\n      <th>ub_99</th>\n      <th>pred_n_gpu_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>...</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.337572</td>\n      <td>6.597421e-08</td>\n      <td>0.328949</td>\n      <td>1.772129e+07</td>\n      <td>2547.051123</td>\n      <td>1.790663e+07</td>\n      <td>0.337572</td>\n      <td>1.790664e+07</td>\n      <td>2573.692874</td>\n      <td>0.337572</td>\n      <td>...</td>\n      <td>2573.692874</td>\n      <td>0.337572</td>\n      <td>1.790664e+07</td>\n      <td>2573.692874</td>\n      <td>0.337573</td>\n      <td>1.790664e+07</td>\n      <td>2573.693261</td>\n      <td>0.337573</td>\n      <td>1.790664e+07</td>\n      <td>2573.693261</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.214559</td>\n      <td>6.558250e-08</td>\n      <td>0.232520</td>\n      <td>4.997830e+06</td>\n      <td>718.189507</td>\n      <td>4.611775e+06</td>\n      <td>0.214559</td>\n      <td>4.611776e+06</td>\n      <td>662.714245</td>\n      <td>0.214559</td>\n      <td>...</td>\n      <td>662.714245</td>\n      <td>0.214559</td>\n      <td>4.611777e+06</td>\n      <td>662.714245</td>\n      <td>0.214559</td>\n      <td>4.611777e+06</td>\n      <td>662.713676</td>\n      <td>0.214559</td>\n      <td>4.611777e+06</td>\n      <td>662.713676</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.039172</td>\n      <td>0.000000e+00</td>\n      <td>-0.172291</td>\n      <td>6.947540e+06</td>\n      <td>999.000000</td>\n      <td>9.808823e+06</td>\n      <td>-0.039172</td>\n      <td>9.808824e+06</td>\n      <td>1410.000000</td>\n      <td>-0.039172</td>\n      <td>...</td>\n      <td>1410.000000</td>\n      <td>-0.039172</td>\n      <td>9.808824e+06</td>\n      <td>1410.000000</td>\n      <td>-0.039172</td>\n      <td>9.808824e+06</td>\n      <td>1410.000000</td>\n      <td>-0.039172</td>\n      <td>9.808824e+06</td>\n      <td>1410.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.125868</td>\n      <td>1.117587e-08</td>\n      <td>0.106536</td>\n      <td>1.294070e+07</td>\n      <td>1860.000000</td>\n      <td>1.335623e+07</td>\n      <td>0.125868</td>\n      <td>1.335623e+07</td>\n      <td>1919.500000</td>\n      <td>0.125868</td>\n      <td>...</td>\n      <td>1919.500000</td>\n      <td>0.125868</td>\n      <td>1.335623e+07</td>\n      <td>1919.500000</td>\n      <td>0.125868</td>\n      <td>1.335623e+07</td>\n      <td>1919.500000</td>\n      <td>0.125868</td>\n      <td>1.335623e+07</td>\n      <td>1919.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.367512</td>\n      <td>5.960465e-08</td>\n      <td>0.362540</td>\n      <td>1.844329e+07</td>\n      <td>2651.000000</td>\n      <td>1.855016e+07</td>\n      <td>0.367512</td>\n      <td>1.855016e+07</td>\n      <td>2666.000000</td>\n      <td>0.367512</td>\n      <td>...</td>\n      <td>2666.000000</td>\n      <td>0.367512</td>\n      <td>1.855016e+07</td>\n      <td>2666.000000</td>\n      <td>0.367512</td>\n      <td>1.855016e+07</td>\n      <td>2666.000000</td>\n      <td>0.367512</td>\n      <td>1.855016e+07</td>\n      <td>2666.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.512203</td>\n      <td>8.940697e-08</td>\n      <td>0.519670</td>\n      <td>2.182068e+07</td>\n      <td>3136.000000</td>\n      <td>2.166017e+07</td>\n      <td>0.512203</td>\n      <td>2.166018e+07</td>\n      <td>3112.750000</td>\n      <td>0.512203</td>\n      <td>...</td>\n      <td>3112.750000</td>\n      <td>0.512203</td>\n      <td>2.166018e+07</td>\n      <td>3112.750000</td>\n      <td>0.512203</td>\n      <td>2.166018e+07</td>\n      <td>3112.750000</td>\n      <td>0.512203</td>\n      <td>2.166018e+07</td>\n      <td>3112.750000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.893295</td>\n      <td>2.980232e-07</td>\n      <td>0.915283</td>\n      <td>3.032405e+07</td>\n      <td>4358.000000</td>\n      <td>2.985144e+07</td>\n      <td>0.893295</td>\n      <td>2.985145e+07</td>\n      <td>4290.000000</td>\n      <td>0.893295</td>\n      <td>...</td>\n      <td>4290.000000</td>\n      <td>0.893295</td>\n      <td>2.985145e+07</td>\n      <td>4290.000000</td>\n      <td>0.893295</td>\n      <td>2.985145e+07</td>\n      <td>4290.000000</td>\n      <td>0.893295</td>\n      <td>2.985145e+07</td>\n      <td>4290.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_results = pd.read_csv(\"output_MCDLSTM-ali20_g-gpu-w288-h2.csv\")\n",
    "monte_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "monte_results[\"model\"] = [\"MCD\" for i in range(len(monte_results))]\n",
    "monte_results.rename(columns={\"avggpu\": \"pred_norm_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = monte_results.pop('model')\n",
    "monte_results.insert(0, 'model', first_column)\n",
    "monte_results[\"true_gpu\"] = scaler.inverse_transform(monte_results[\"true_norm_gpu\"].values.reshape(-1,1))\n",
    "monte_results[\"true_n_gpu\"] = monte_results.apply(lambda row: math.ceil(row[\"true_gpu\"]/gpu_no_norm_conv_value), axis=1)\n",
    "# monte_results.drop(columns=['true_norm_gpu'], inplace=True)\n",
    "monte_results[\"pred_gpu\"] = scaler.inverse_transform(monte_results[\"pred_norm_gpu\"].values.reshape(-1,1))\n",
    "\n",
    "for target in target_qos:\n",
    "    alpa = float(int(target)/100)\n",
    "    monte_results[f\"ub_{target}_norm\"] = monte_results.apply(lambda row: find_upper_bound(row[\"pred_norm_gpu\"], row[\"pred_std\"], alpha=alpa), axis=1)\n",
    "    monte_results[f\"ub_{target}\"] = scaler.inverse_transform(monte_results[f\"ub_{target}_norm\"].values.reshape(-1,1))\n",
    "    monte_results[f\"pred_n_gpu_{target}\"] = monte_results.apply(lambda row: math.ceil(row[f\"ub_{target}\"]/gpu_no_norm_conv_value), axis=1)\n",
    "monte_results.to_csv(\"scenarios/monte_results.csv\")\n",
    "monte_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:45.046708432Z",
     "start_time": "2023-06-29T08:09:41.483487118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:45.150139170Z",
     "start_time": "2023-06-29T08:09:45.044437854Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "       pred_norm_gpu     pred_std  true_norm_gpu      true_gpu   true_n_gpu  \\\ncount    2582.000000  2582.000000    2582.000000  2.582000e+03  2582.000000   \nmean        0.362692     0.066016       0.328949  1.772129e+07  2547.051123   \nstd         0.160845     0.010062       0.232520  4.997830e+06   718.189507   \nmin         0.128860     0.043463      -0.172291  6.947540e+06   999.000000   \n25%         0.163772     0.053720       0.106536  1.294070e+07  1860.000000   \n50%         0.404047     0.070484       0.362540  1.844329e+07  2651.000000   \n75%         0.510996     0.074996       0.519670  2.182068e+07  3136.000000   \nmax         0.619214     0.090434       0.915283  3.032405e+07  4358.000000   \n\n           pred_gpu   ub_90_norm         ub_90  pred_n_gpu_90   ub_91_norm  \\\ncount  2.582000e+03  2582.000000  2.582000e+03    2582.000000  2582.000000   \nmean   1.844655e+07     0.447295  2.026503e+07    2912.587529     0.451203   \nstd    3.457235e+06     0.172483  3.707383e+06     532.743167     0.173025   \nmin    1.342052e+07     0.198997  1.492808e+07    2146.000000     0.202238   \n25%    1.417095e+07     0.230023  1.559494e+07    2241.250000     0.233086   \n50%    1.933546e+07     0.496730  2.132760e+07    3065.000000     0.500986   \n75%    2.163423e+07     0.608714  2.373460e+07    3411.000000     0.613219   \nmax    2.396029e+07     0.699979  2.569626e+07    3693.000000     0.703710   \n\n       ...  pred_n_gpu_96   ub_97_norm         ub_97  pred_n_gpu_97  \\\ncount  ...    2582.000000  2582.000000  2.582000e+03    2582.000000   \nmean   ...    3008.252905     0.486855  2.111534e+07    3034.780790   \nstd    ...     546.049709     0.177984  3.825629e+06     549.741435   \nmin    ...    2225.000000     0.231793  1.563300e+07    2247.000000   \n25%    ...    2316.250000     0.261072  1.626231e+07    2337.250000   \n50%    ...    3169.500000     0.539615  2.224938e+07    3198.000000   \n75%    ...    3522.000000     0.654395  2.471648e+07    3552.000000   \nmax    ...    3784.000000     0.737744  2.650799e+07    3810.000000   \n\n        ub_98_norm         ub_98  pred_n_gpu_98   ub_99_norm         ub_99  \\\ncount  2582.000000  2.582000e+03    2582.000000  2582.000000  2.582000e+03   \nmean      0.498273  2.136076e+07    3070.043377     0.516269  2.174757e+07   \nstd       0.179578  3.859893e+06     554.664675     0.182096  3.914014e+06   \nmin       0.241259  1.583645e+07    2276.000000     0.256178  1.615713e+07   \n25%       0.270133  1.645707e+07    2365.250000     0.284297  1.676152e+07   \n50%       0.551925  2.251397e+07    3236.000000     0.571510  2.293493e+07   \n75%       0.667527  2.499874e+07    3593.000000     0.688476  2.544902e+07   \nmax       0.748643  2.674227e+07    3843.000000     0.765823  2.711153e+07   \n\n       pred_n_gpu_99  \ncount    2582.000000  \nmean     3125.620837  \nstd       562.443335  \nmin      2322.000000  \n25%      2409.000000  \n50%      3296.500000  \n75%      3657.750000  \nmax      3896.000000  \n\n[8 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_norm_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>pred_gpu</th>\n      <th>ub_90_norm</th>\n      <th>ub_90</th>\n      <th>pred_n_gpu_90</th>\n      <th>ub_91_norm</th>\n      <th>...</th>\n      <th>pred_n_gpu_96</th>\n      <th>ub_97_norm</th>\n      <th>ub_97</th>\n      <th>pred_n_gpu_97</th>\n      <th>ub_98_norm</th>\n      <th>ub_98</th>\n      <th>pred_n_gpu_98</th>\n      <th>ub_99_norm</th>\n      <th>ub_99</th>\n      <th>pred_n_gpu_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>...</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.362692</td>\n      <td>0.066016</td>\n      <td>0.328949</td>\n      <td>1.772129e+07</td>\n      <td>2547.051123</td>\n      <td>1.844655e+07</td>\n      <td>0.447295</td>\n      <td>2.026503e+07</td>\n      <td>2912.587529</td>\n      <td>0.451203</td>\n      <td>...</td>\n      <td>3008.252905</td>\n      <td>0.486855</td>\n      <td>2.111534e+07</td>\n      <td>3034.780790</td>\n      <td>0.498273</td>\n      <td>2.136076e+07</td>\n      <td>3070.043377</td>\n      <td>0.516269</td>\n      <td>2.174757e+07</td>\n      <td>3125.620837</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.160845</td>\n      <td>0.010062</td>\n      <td>0.232520</td>\n      <td>4.997830e+06</td>\n      <td>718.189507</td>\n      <td>3.457235e+06</td>\n      <td>0.172483</td>\n      <td>3.707383e+06</td>\n      <td>532.743167</td>\n      <td>0.173025</td>\n      <td>...</td>\n      <td>546.049709</td>\n      <td>0.177984</td>\n      <td>3.825629e+06</td>\n      <td>549.741435</td>\n      <td>0.179578</td>\n      <td>3.859893e+06</td>\n      <td>554.664675</td>\n      <td>0.182096</td>\n      <td>3.914014e+06</td>\n      <td>562.443335</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.128860</td>\n      <td>0.043463</td>\n      <td>-0.172291</td>\n      <td>6.947540e+06</td>\n      <td>999.000000</td>\n      <td>1.342052e+07</td>\n      <td>0.198997</td>\n      <td>1.492808e+07</td>\n      <td>2146.000000</td>\n      <td>0.202238</td>\n      <td>...</td>\n      <td>2225.000000</td>\n      <td>0.231793</td>\n      <td>1.563300e+07</td>\n      <td>2247.000000</td>\n      <td>0.241259</td>\n      <td>1.583645e+07</td>\n      <td>2276.000000</td>\n      <td>0.256178</td>\n      <td>1.615713e+07</td>\n      <td>2322.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.163772</td>\n      <td>0.053720</td>\n      <td>0.106536</td>\n      <td>1.294070e+07</td>\n      <td>1860.000000</td>\n      <td>1.417095e+07</td>\n      <td>0.230023</td>\n      <td>1.559494e+07</td>\n      <td>2241.250000</td>\n      <td>0.233086</td>\n      <td>...</td>\n      <td>2316.250000</td>\n      <td>0.261072</td>\n      <td>1.626231e+07</td>\n      <td>2337.250000</td>\n      <td>0.270133</td>\n      <td>1.645707e+07</td>\n      <td>2365.250000</td>\n      <td>0.284297</td>\n      <td>1.676152e+07</td>\n      <td>2409.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.404047</td>\n      <td>0.070484</td>\n      <td>0.362540</td>\n      <td>1.844329e+07</td>\n      <td>2651.000000</td>\n      <td>1.933546e+07</td>\n      <td>0.496730</td>\n      <td>2.132760e+07</td>\n      <td>3065.000000</td>\n      <td>0.500986</td>\n      <td>...</td>\n      <td>3169.500000</td>\n      <td>0.539615</td>\n      <td>2.224938e+07</td>\n      <td>3198.000000</td>\n      <td>0.551925</td>\n      <td>2.251397e+07</td>\n      <td>3236.000000</td>\n      <td>0.571510</td>\n      <td>2.293493e+07</td>\n      <td>3296.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.510996</td>\n      <td>0.074996</td>\n      <td>0.519670</td>\n      <td>2.182068e+07</td>\n      <td>3136.000000</td>\n      <td>2.163423e+07</td>\n      <td>0.608714</td>\n      <td>2.373460e+07</td>\n      <td>3411.000000</td>\n      <td>0.613219</td>\n      <td>...</td>\n      <td>3522.000000</td>\n      <td>0.654395</td>\n      <td>2.471648e+07</td>\n      <td>3552.000000</td>\n      <td>0.667527</td>\n      <td>2.499874e+07</td>\n      <td>3593.000000</td>\n      <td>0.688476</td>\n      <td>2.544902e+07</td>\n      <td>3657.750000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.619214</td>\n      <td>0.090434</td>\n      <td>0.915283</td>\n      <td>3.032405e+07</td>\n      <td>4358.000000</td>\n      <td>2.396029e+07</td>\n      <td>0.699979</td>\n      <td>2.569626e+07</td>\n      <td>3693.000000</td>\n      <td>0.703710</td>\n      <td>...</td>\n      <td>3784.000000</td>\n      <td>0.737744</td>\n      <td>2.650799e+07</td>\n      <td>3810.000000</td>\n      <td>0.748643</td>\n      <td>2.674227e+07</td>\n      <td>3843.000000</td>\n      <td>0.765823</td>\n      <td>2.711153e+07</td>\n      <td>3896.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flbnn_results = pd.read_csv(\"output_FLBNN-ali20_g-gpu-w288-h2.csv\")\n",
    "flbnn_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "flbnn_results[\"model\"] = [\"HBNN++\" for i in range(len(flbnn_results))]\n",
    "flbnn_results.rename(columns={\"avggpu\": \"pred_norm_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = flbnn_results.pop('model')\n",
    "flbnn_results.insert(0, 'model', first_column)\n",
    "flbnn_results[\"true_gpu\"] = scaler.inverse_transform(flbnn_results[\"true_norm_gpu\"].values.reshape(-1,1))\n",
    "flbnn_results[\"true_n_gpu\"] = flbnn_results.apply(lambda row: math.ceil(row[\"true_gpu\"]/gpu_no_norm_conv_value), axis=1)\n",
    "# flbnn_results.drop(columns=['true_norm_gpu'], inplace=True)\n",
    "flbnn_results[\"pred_gpu\"] = scaler.inverse_transform(flbnn_results[\"pred_norm_gpu\"].values.reshape(-1,1))\n",
    "\n",
    "for target in target_qos:\n",
    "    alpa = float(int(target)/100)\n",
    "    flbnn_results[f\"ub_{target}_norm\"] = flbnn_results.apply(lambda row: find_upper_bound(row[\"pred_norm_gpu\"], row[\"pred_std\"], alpha=alpa), axis=1)\n",
    "    flbnn_results[f\"ub_{target}\"] = scaler.inverse_transform(flbnn_results[f\"ub_{target}_norm\"].values.reshape(-1,1))\n",
    "    flbnn_results[f\"pred_n_gpu_{target}\"] = flbnn_results.apply(lambda row: math.ceil(row[f\"ub_{target}\"]/gpu_no_norm_conv_value), axis=1)\n",
    "flbnn_results.to_csv(\"scenarios/flbnn_results.csv\")\n",
    "flbnn_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:48.375203902Z",
     "start_time": "2023-06-29T08:09:45.088082665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:48.497759931Z",
     "start_time": "2023-06-29T08:09:48.371826772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       pred_norm_gpu  pred_std  true_norm_gpu      true_gpu   true_n_gpu  \\\ncount    2582.000000    2582.0    2582.000000  2.582000e+03  2582.000000   \nmean        0.401227       0.0       0.328949  1.772129e+07  2547.051123   \nstd         0.227837       0.0       0.232520  4.997830e+06   718.189507   \nmin         0.005820       0.0      -0.172291  6.947540e+06   999.000000   \n25%         0.190937       0.0       0.106536  1.294070e+07  1860.000000   \n50%         0.431730       0.0       0.362540  1.844329e+07  2651.000000   \n75%         0.588165       0.0       0.519670  2.182068e+07  3136.000000   \nmax         0.982749       0.0       0.915283  3.032405e+07  4358.000000   \n\n        ub_90_norm         ub_90  pred_n_gpu_90   ub_91_norm         ub_91  \\\ncount  2582.000000  2.582000e+03    2582.000000  2582.000000  2.582000e+03   \nmean      0.365301  1.850264e+07    2659.324555     0.379118  1.879962e+07   \nstd       0.227710  4.894433e+06     703.334291     0.229850  4.940434e+06   \nmin      -0.044874  9.686262e+06    1392.000000    -0.011003  1.041430e+07   \n25%       0.147834  1.382836e+07    1988.000000     0.155301  1.398885e+07   \n50%       0.398979  1.922653e+07    2763.000000     0.411144  1.948800e+07   \n75%       0.551565  2.250622e+07    3234.750000     0.568246  2.286477e+07   \nmax       0.910586  3.022311e+07    4344.000000     0.961678  3.132128e+07   \n\n       ...  pred_n_gpu_96   ub_97_norm         ub_97  pred_n_gpu_97  \\\ncount  ...    2582.000000  2582.000000  2.582000e+03    2582.000000   \nmean   ...    2810.230054     0.410383  1.947165e+07    2798.585980   \nstd    ...     678.332355     0.200764  4.315268e+06     620.102623   \nmin    ...    1711.000000     0.065909  1.206745e+07    1735.000000   \n25%    ...    2146.500000     0.223268  1.544976e+07    2220.250000   \n50%    ...    2888.000000     0.428514  1.986135e+07    2854.500000   \n75%    ...    3370.500000     0.574925  2.300833e+07    3307.000000   \nmax    ...    4444.000000     0.927526  3.058721e+07    4396.000000   \n\n        ub_98_norm         ub_98  pred_n_gpu_98   ub_99_norm         ub_99  \\\ncount  2582.000000  2.582000e+03    2582.000000  2582.000000  2.582000e+03   \nmean      0.449391  2.031008e+07    2919.060031     0.504672  2.149830e+07   \nstd       0.205721  4.421812e+06     635.423755     0.203512  4.374329e+06   \nmin       0.089352  1.257133e+07    1807.000000     0.136283  1.358009e+07   \n25%       0.256659  1.616747e+07    2324.000000     0.317426  1.747360e+07   \n50%       0.465056  2.064679e+07    2967.500000     0.525413  2.194413e+07   \n75%       0.616106  2.389349e+07    3434.000000     0.663141  2.490447e+07   \nmax       0.988798  3.190420e+07    4585.000000     1.035353  3.290486e+07   \n\n       pred_n_gpu_99  \ncount    2582.000000  \nmean     3089.815647  \nstd       628.588877  \nmin      1952.000000  \n25%      2511.500000  \n50%      3154.000000  \n75%      3579.000000  \nmax      4729.000000  \n\n[8 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_norm_gpu</th>\n      <th>pred_std</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>ub_90_norm</th>\n      <th>ub_90</th>\n      <th>pred_n_gpu_90</th>\n      <th>ub_91_norm</th>\n      <th>ub_91</th>\n      <th>...</th>\n      <th>pred_n_gpu_96</th>\n      <th>ub_97_norm</th>\n      <th>ub_97</th>\n      <th>pred_n_gpu_97</th>\n      <th>ub_98_norm</th>\n      <th>ub_98</th>\n      <th>pred_n_gpu_98</th>\n      <th>ub_99_norm</th>\n      <th>ub_99</th>\n      <th>pred_n_gpu_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2582.000000</td>\n      <td>2582.0</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>...</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.401227</td>\n      <td>0.0</td>\n      <td>0.328949</td>\n      <td>1.772129e+07</td>\n      <td>2547.051123</td>\n      <td>0.365301</td>\n      <td>1.850264e+07</td>\n      <td>2659.324555</td>\n      <td>0.379118</td>\n      <td>1.879962e+07</td>\n      <td>...</td>\n      <td>2810.230054</td>\n      <td>0.410383</td>\n      <td>1.947165e+07</td>\n      <td>2798.585980</td>\n      <td>0.449391</td>\n      <td>2.031008e+07</td>\n      <td>2919.060031</td>\n      <td>0.504672</td>\n      <td>2.149830e+07</td>\n      <td>3089.815647</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.227837</td>\n      <td>0.0</td>\n      <td>0.232520</td>\n      <td>4.997830e+06</td>\n      <td>718.189507</td>\n      <td>0.227710</td>\n      <td>4.894433e+06</td>\n      <td>703.334291</td>\n      <td>0.229850</td>\n      <td>4.940434e+06</td>\n      <td>...</td>\n      <td>678.332355</td>\n      <td>0.200764</td>\n      <td>4.315268e+06</td>\n      <td>620.102623</td>\n      <td>0.205721</td>\n      <td>4.421812e+06</td>\n      <td>635.423755</td>\n      <td>0.203512</td>\n      <td>4.374329e+06</td>\n      <td>628.588877</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.005820</td>\n      <td>0.0</td>\n      <td>-0.172291</td>\n      <td>6.947540e+06</td>\n      <td>999.000000</td>\n      <td>-0.044874</td>\n      <td>9.686262e+06</td>\n      <td>1392.000000</td>\n      <td>-0.011003</td>\n      <td>1.041430e+07</td>\n      <td>...</td>\n      <td>1711.000000</td>\n      <td>0.065909</td>\n      <td>1.206745e+07</td>\n      <td>1735.000000</td>\n      <td>0.089352</td>\n      <td>1.257133e+07</td>\n      <td>1807.000000</td>\n      <td>0.136283</td>\n      <td>1.358009e+07</td>\n      <td>1952.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.190937</td>\n      <td>0.0</td>\n      <td>0.106536</td>\n      <td>1.294070e+07</td>\n      <td>1860.000000</td>\n      <td>0.147834</td>\n      <td>1.382836e+07</td>\n      <td>1988.000000</td>\n      <td>0.155301</td>\n      <td>1.398885e+07</td>\n      <td>...</td>\n      <td>2146.500000</td>\n      <td>0.223268</td>\n      <td>1.544976e+07</td>\n      <td>2220.250000</td>\n      <td>0.256659</td>\n      <td>1.616747e+07</td>\n      <td>2324.000000</td>\n      <td>0.317426</td>\n      <td>1.747360e+07</td>\n      <td>2511.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.431730</td>\n      <td>0.0</td>\n      <td>0.362540</td>\n      <td>1.844329e+07</td>\n      <td>2651.000000</td>\n      <td>0.398979</td>\n      <td>1.922653e+07</td>\n      <td>2763.000000</td>\n      <td>0.411144</td>\n      <td>1.948800e+07</td>\n      <td>...</td>\n      <td>2888.000000</td>\n      <td>0.428514</td>\n      <td>1.986135e+07</td>\n      <td>2854.500000</td>\n      <td>0.465056</td>\n      <td>2.064679e+07</td>\n      <td>2967.500000</td>\n      <td>0.525413</td>\n      <td>2.194413e+07</td>\n      <td>3154.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.588165</td>\n      <td>0.0</td>\n      <td>0.519670</td>\n      <td>2.182068e+07</td>\n      <td>3136.000000</td>\n      <td>0.551565</td>\n      <td>2.250622e+07</td>\n      <td>3234.750000</td>\n      <td>0.568246</td>\n      <td>2.286477e+07</td>\n      <td>...</td>\n      <td>3370.500000</td>\n      <td>0.574925</td>\n      <td>2.300833e+07</td>\n      <td>3307.000000</td>\n      <td>0.616106</td>\n      <td>2.389349e+07</td>\n      <td>3434.000000</td>\n      <td>0.663141</td>\n      <td>2.490447e+07</td>\n      <td>3579.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.982749</td>\n      <td>0.0</td>\n      <td>0.915283</td>\n      <td>3.032405e+07</td>\n      <td>4358.000000</td>\n      <td>0.910586</td>\n      <td>3.022311e+07</td>\n      <td>4344.000000</td>\n      <td>0.961678</td>\n      <td>3.132128e+07</td>\n      <td>...</td>\n      <td>4444.000000</td>\n      <td>0.927526</td>\n      <td>3.058721e+07</td>\n      <td>4396.000000</td>\n      <td>0.988798</td>\n      <td>3.190420e+07</td>\n      <td>4585.000000</td>\n      <td>1.035353</td>\n      <td>3.290486e+07</td>\n      <td>4729.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmq_results = pd.read_csv(\"LSTMQ/output_LSTMQ-0.95-ali20_g-gpu-w288-h2.csv\")\n",
    "lstmq_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "lstmq_results[\"model\"] = [\"LSTMQ\" for i in range(len(lstmq_results))]\n",
    "lstmq_results.rename(columns={\"avggpu\": \"pred_norm_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = lstmq_results.pop('model')\n",
    "lstmq_results.insert(0, 'model', first_column)\n",
    "lstmq_results[\"true_gpu\"] = scaler.inverse_transform(lstmq_results[\"true_norm_gpu\"].values.reshape(-1,1))\n",
    "lstmq_results[\"true_n_gpu\"] = lstmq_results.apply(lambda row: math.ceil(row[\"true_gpu\"]/gpu_no_norm_conv_value), axis=1)\n",
    "# lstmq_results.drop(columns=['true_norm_gpu'], inplace=True)\n",
    "\n",
    "for target in target_qos:\n",
    "    alpa = float(int(target)/100)\n",
    "    target_results = pd.read_csv(f\"LSTMQ/output_LSTMQ-{alpa}-ali20_g-gpu-w288-h2.csv\")\n",
    "    lstmq_results[f\"ub_{target}_norm\"] = target_results.apply(lambda row: find_upper_bound(row[\"avggpu\"], row[\"std\"], alpha=alpa), axis=1)\n",
    "    lstmq_results[f\"ub_{target}\"] = scaler.inverse_transform(lstmq_results[f\"ub_{target}_norm\"].values.reshape(-1,1))\n",
    "    lstmq_results[f\"pred_n_gpu_{target}\"] = lstmq_results.apply(lambda row: math.ceil(row[f\"ub_{target}\"]/gpu_no_norm_conv_value), axis=1)\n",
    "lstmq_results.to_csv(\"scenarios/lstmq_results.csv\")\n",
    "lstmq_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:52.164678332Z",
     "start_time": "2023-06-29T08:09:48.420017971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:52.165006772Z",
     "start_time": "2023-06-29T08:09:52.092674021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:52.165192664Z",
     "start_time": "2023-06-29T08:09:52.096791730Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  model  pred_norm_gpu  true_norm_gpu      true_gpu  true_n_gpu      pred_gpu  \\\n0  LSTM       0.835576       0.804885  2.795113e+07        4017  2.861081e+07   \n1  LSTM       0.822173       0.814360  2.815480e+07        4046  2.832273e+07   \n\n   ub_90_norm         ub_90  pred_n_gpu_90  ub_91_norm  ...  pred_n_gpu_96  \\\n0    0.848391  2.888627e+07           4151    0.848983  ...           4166   \n1    0.834988  2.859819e+07           4110    0.835580  ...           4125   \n\n   ub_97_norm         ub_97  pred_n_gpu_97  ub_98_norm         ub_98  \\\n0    0.854384  2.901507e+07           4170    0.856113  2.905225e+07   \n1    0.840981  2.872699e+07           4129    0.842710  2.876417e+07   \n\n   pred_n_gpu_98  ub_99_norm         ub_99  pred_n_gpu_99  \n0           4175    0.858839  2.911084e+07           4184  \n1           4134    0.845436  2.882276e+07           4142  \n\n[2 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>pred_norm_gpu</th>\n      <th>true_norm_gpu</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>pred_gpu</th>\n      <th>ub_90_norm</th>\n      <th>ub_90</th>\n      <th>pred_n_gpu_90</th>\n      <th>ub_91_norm</th>\n      <th>...</th>\n      <th>pred_n_gpu_96</th>\n      <th>ub_97_norm</th>\n      <th>ub_97</th>\n      <th>pred_n_gpu_97</th>\n      <th>ub_98_norm</th>\n      <th>ub_98</th>\n      <th>pred_n_gpu_98</th>\n      <th>ub_99_norm</th>\n      <th>ub_99</th>\n      <th>pred_n_gpu_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LSTM</td>\n      <td>0.835576</td>\n      <td>0.804885</td>\n      <td>2.795113e+07</td>\n      <td>4017</td>\n      <td>2.861081e+07</td>\n      <td>0.848391</td>\n      <td>2.888627e+07</td>\n      <td>4151</td>\n      <td>0.848983</td>\n      <td>...</td>\n      <td>4166</td>\n      <td>0.854384</td>\n      <td>2.901507e+07</td>\n      <td>4170</td>\n      <td>0.856113</td>\n      <td>2.905225e+07</td>\n      <td>4175</td>\n      <td>0.858839</td>\n      <td>2.911084e+07</td>\n      <td>4184</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LSTM</td>\n      <td>0.822173</td>\n      <td>0.814360</td>\n      <td>2.815480e+07</td>\n      <td>4046</td>\n      <td>2.832273e+07</td>\n      <td>0.834988</td>\n      <td>2.859819e+07</td>\n      <td>4110</td>\n      <td>0.835580</td>\n      <td>...</td>\n      <td>4125</td>\n      <td>0.840981</td>\n      <td>2.872699e+07</td>\n      <td>4129</td>\n      <td>0.842710</td>\n      <td>2.876417e+07</td>\n      <td>4134</td>\n      <td>0.845436</td>\n      <td>2.882276e+07</td>\n      <td>4142</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_results = pd.read_csv(\"output_LSTM-ali20_g-gpu-w288-h2.csv\")\n",
    "lstm_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "lstm_results[\"model\"] = [\"LSTM\" for i in range(len(lstm_results))]\n",
    "lstm_results.rename(columns={\"avggpu\": \"pred_norm_gpu\", \"std\": \"pred_std\", \"labels\": \"true_norm_gpu\"}, inplace=True)\n",
    "first_column = lstm_results.pop('model')\n",
    "lstm_results.insert(0, 'model', first_column)\n",
    "lstm_results[\"true_gpu\"] = scaler.inverse_transform(lstm_results[\"true_norm_gpu\"].values.reshape(-1,1))\n",
    "lstm_results[\"true_n_gpu\"] = lstm_results.apply(lambda row: math.ceil(row[\"true_gpu\"]/gpu_no_norm_conv_value), axis=1)\n",
    "lstm_results[\"pred_gpu\"] = scaler.inverse_transform(lstm_results[\"pred_norm_gpu\"].values.reshape(-1,1))\n",
    "\n",
    "df_train = pd.read_csv(\"output_train-LSTM-ali20_g-gpu-w288-h2.csv\")\n",
    "for target in target_qos:\n",
    "    alpa = float(int(target)/100)\n",
    "    train_std = find_optimal_std_lstm(df_train, alpa, 288)\n",
    "    lstm_results[f\"ub_{target}_norm\"] = lstm_results.apply(lambda row: find_upper_bound(row[\"pred_norm_gpu\"], train_std, alpha=alpa), axis=1)\n",
    "    lstm_results[f\"ub_{target}\"] = scaler.inverse_transform(lstm_results[f\"ub_{target}_norm\"].values.reshape(-1,1))\n",
    "    lstm_results[f\"pred_n_gpu_{target}\"] = lstm_results.apply(lambda row: math.ceil(row[f\"ub_{target}\"]/gpu_no_norm_conv_value), axis=1)\n",
    "lstm_results.to_csv(\"scenarios/lstm_results.csv\")\n",
    "lstm_results.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T08:09:56.203499361Z",
     "start_time": "2023-06-29T08:09:52.141193938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:22:14.509106362Z",
     "start_time": "2023-06-28T15:22:14.477266873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:22:14.725134720Z",
     "start_time": "2023-06-28T15:22:14.719028829Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "           pred_gpu      pred_std      true_gpu   true_n_gpu  pred_norm_gpu  \\\ncount  2.582000e+03  2.582000e+03  2.582000e+03  2582.000000    2582.000000   \nmean   2.106272e+07  1.903099e+06  1.822752e+07  2619.806352       0.452041   \nstd    5.309325e+06  9.079618e+04  5.355664e+06   769.605537       0.230508   \nmin    1.050380e+07  1.632153e+06  6.682396e+06   961.000000      -0.006382   \n25%    1.659927e+07  1.839257e+06  1.310465e+07  1884.000000       0.258258   \n50%    2.162321e+07  1.902470e+06  1.900122e+07  2731.000000       0.476376   \n75%    2.561570e+07  1.960874e+06  2.262042e+07  3251.000000       0.649713   \nmax    2.825445e+07  2.232411e+06  3.173261e+07  4560.000000       0.764276   \n\n       true_norm_gpu         ub_90   ub_90_norm  pred_n_gpu_90         ub_91  \\\ncount    2582.000000  2.582000e+03  2582.000000    2582.000000  2.582000e+03   \nmean        0.328949  2.350164e+07     0.557929    3377.688613  2.361431e+07   \nstd         0.232520  5.337168e+06     0.231717     766.958987  5.338512e+06   \nmin        -0.172291  1.284332e+07     0.095190    1846.000000  1.294894e+07   \n25%         0.106536  1.907005e+07     0.365529    2741.000000  1.918398e+07   \n50%         0.362540  2.406783e+07     0.582510    3459.000000  2.417746e+07   \n75%         0.519670  2.811876e+07     0.758385    4041.000000  2.823361e+07   \nmax         0.915283  3.077205e+07     0.873579    4422.000000  3.089044e+07   \n\n       ...  pred_n_gpu_96         ub_97   ub_97_norm  pred_n_gpu_97  \\\ncount  ...    2582.000000  2.582000e+03  2582.000000    2582.000000   \nmean   ...    3505.984895  2.464205e+07     0.607441    3541.573199   \nstd    ...     768.498467  5.351005e+06     0.232318     768.935133   \nmin    ...    1966.000000  1.391238e+07     0.141604    2000.000000   \n25%    ...    2871.500000  2.022521e+07     0.415680    2907.000000   \n50%    ...    3584.000000  2.517233e+07     0.630463    3618.000000   \n75%    ...    4173.000000  2.929581e+07     0.809487    4210.000000   \nmax    ...    4558.000000  3.197456e+07     0.925787    4595.000000   \n\n              ub_98   ub_98_norm  pred_n_gpu_98         ub_99   ub_99_norm  \\\ncount  2.582000e+03  2582.000000    2582.000000  2.582000e+03  2582.000000   \nmean   2.497120e+07     0.621731    3588.863284  2.548999e+07     0.644255   \nstd    5.355095e+06     0.232495     769.528759  5.361629e+06     0.232779   \nmin    1.422094e+07     0.155001    2044.000000  1.470726e+07     0.176115   \n25%    2.055349e+07     0.429933    2954.250000  2.107646e+07     0.452638   \n50%    2.548633e+07     0.644096    3663.000000  2.599987e+07     0.666392   \n75%    2.963872e+07     0.824375    4259.750000  3.018105e+07     0.847920   \nmax    3.232222e+07     0.940881    4645.000000  3.287018e+07     0.964671   \n\n       pred_n_gpu_99  \ncount    2582.000000  \nmean     3663.410147  \nstd       770.459352  \nmin      2114.000000  \n25%      3029.250000  \n50%      3737.000000  \n75%      4337.750000  \nmax      4724.000000  \n\n[8 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_gpu</th>\n      <th>pred_std</th>\n      <th>true_gpu</th>\n      <th>true_n_gpu</th>\n      <th>pred_norm_gpu</th>\n      <th>true_norm_gpu</th>\n      <th>ub_90</th>\n      <th>ub_90_norm</th>\n      <th>pred_n_gpu_90</th>\n      <th>ub_91</th>\n      <th>...</th>\n      <th>pred_n_gpu_96</th>\n      <th>ub_97</th>\n      <th>ub_97_norm</th>\n      <th>pred_n_gpu_97</th>\n      <th>ub_98</th>\n      <th>ub_98_norm</th>\n      <th>pred_n_gpu_98</th>\n      <th>ub_99</th>\n      <th>ub_99_norm</th>\n      <th>pred_n_gpu_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.582000e+03</td>\n      <td>2.582000e+03</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>...</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n      <td>2.582000e+03</td>\n      <td>2582.000000</td>\n      <td>2582.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.106272e+07</td>\n      <td>1.903099e+06</td>\n      <td>1.822752e+07</td>\n      <td>2619.806352</td>\n      <td>0.452041</td>\n      <td>0.328949</td>\n      <td>2.350164e+07</td>\n      <td>0.557929</td>\n      <td>3377.688613</td>\n      <td>2.361431e+07</td>\n      <td>...</td>\n      <td>3505.984895</td>\n      <td>2.464205e+07</td>\n      <td>0.607441</td>\n      <td>3541.573199</td>\n      <td>2.497120e+07</td>\n      <td>0.621731</td>\n      <td>3588.863284</td>\n      <td>2.548999e+07</td>\n      <td>0.644255</td>\n      <td>3663.410147</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.309325e+06</td>\n      <td>9.079618e+04</td>\n      <td>5.355664e+06</td>\n      <td>769.605537</td>\n      <td>0.230508</td>\n      <td>0.232520</td>\n      <td>5.337168e+06</td>\n      <td>0.231717</td>\n      <td>766.958987</td>\n      <td>5.338512e+06</td>\n      <td>...</td>\n      <td>768.498467</td>\n      <td>5.351005e+06</td>\n      <td>0.232318</td>\n      <td>768.935133</td>\n      <td>5.355095e+06</td>\n      <td>0.232495</td>\n      <td>769.528759</td>\n      <td>5.361629e+06</td>\n      <td>0.232779</td>\n      <td>770.459352</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.050380e+07</td>\n      <td>1.632153e+06</td>\n      <td>6.682396e+06</td>\n      <td>961.000000</td>\n      <td>-0.006382</td>\n      <td>-0.172291</td>\n      <td>1.284332e+07</td>\n      <td>0.095190</td>\n      <td>1846.000000</td>\n      <td>1.294894e+07</td>\n      <td>...</td>\n      <td>1966.000000</td>\n      <td>1.391238e+07</td>\n      <td>0.141604</td>\n      <td>2000.000000</td>\n      <td>1.422094e+07</td>\n      <td>0.155001</td>\n      <td>2044.000000</td>\n      <td>1.470726e+07</td>\n      <td>0.176115</td>\n      <td>2114.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.659927e+07</td>\n      <td>1.839257e+06</td>\n      <td>1.310465e+07</td>\n      <td>1884.000000</td>\n      <td>0.258258</td>\n      <td>0.106536</td>\n      <td>1.907005e+07</td>\n      <td>0.365529</td>\n      <td>2741.000000</td>\n      <td>1.918398e+07</td>\n      <td>...</td>\n      <td>2871.500000</td>\n      <td>2.022521e+07</td>\n      <td>0.415680</td>\n      <td>2907.000000</td>\n      <td>2.055349e+07</td>\n      <td>0.429933</td>\n      <td>2954.250000</td>\n      <td>2.107646e+07</td>\n      <td>0.452638</td>\n      <td>3029.250000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.162321e+07</td>\n      <td>1.902470e+06</td>\n      <td>1.900122e+07</td>\n      <td>2731.000000</td>\n      <td>0.476376</td>\n      <td>0.362540</td>\n      <td>2.406783e+07</td>\n      <td>0.582510</td>\n      <td>3459.000000</td>\n      <td>2.417746e+07</td>\n      <td>...</td>\n      <td>3584.000000</td>\n      <td>2.517233e+07</td>\n      <td>0.630463</td>\n      <td>3618.000000</td>\n      <td>2.548633e+07</td>\n      <td>0.644096</td>\n      <td>3663.000000</td>\n      <td>2.599987e+07</td>\n      <td>0.666392</td>\n      <td>3737.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.561570e+07</td>\n      <td>1.960874e+06</td>\n      <td>2.262042e+07</td>\n      <td>3251.000000</td>\n      <td>0.649713</td>\n      <td>0.519670</td>\n      <td>2.811876e+07</td>\n      <td>0.758385</td>\n      <td>4041.000000</td>\n      <td>2.823361e+07</td>\n      <td>...</td>\n      <td>4173.000000</td>\n      <td>2.929581e+07</td>\n      <td>0.809487</td>\n      <td>4210.000000</td>\n      <td>2.963872e+07</td>\n      <td>0.824375</td>\n      <td>4259.750000</td>\n      <td>3.018105e+07</td>\n      <td>0.847920</td>\n      <td>4337.750000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.825445e+07</td>\n      <td>2.232411e+06</td>\n      <td>3.173261e+07</td>\n      <td>4560.000000</td>\n      <td>0.764276</td>\n      <td>0.915283</td>\n      <td>3.077205e+07</td>\n      <td>0.873579</td>\n      <td>4422.000000</td>\n      <td>3.089044e+07</td>\n      <td>...</td>\n      <td>4558.000000</td>\n      <td>3.197456e+07</td>\n      <td>0.925787</td>\n      <td>4595.000000</td>\n      <td>3.232222e+07</td>\n      <td>0.940881</td>\n      <td>4645.000000</td>\n      <td>3.287018e+07</td>\n      <td>0.964671</td>\n      <td>4724.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_results = pd.read_csv(\"prophet.csv\")\n",
    "prophet_results.drop(labels=[\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "prophet_results[\"model\"] = [\"PROPHET\" for i in range(len(prophet_results))]\n",
    "prophet_results.rename(columns={\"avggpu\": \"pred_gpu\", \"std\": \"pred_std\", \"labels\": \"true_gpu\"}, inplace=True)\n",
    "first_column = prophet_results.pop('model')\n",
    "prophet_results.insert(0, 'model', first_column)\n",
    "prophet_results[\"true_n_gpu\"] = prophet_results.apply(lambda row: math.ceil(row[\"true_gpu\"]/gpu_no_norm_conv_value), axis=1)\n",
    "\n",
    "scaler_prophet = MinMaxScaler()\n",
    "factor = .8\n",
    "scaler_prophet.fit(original_dataset.avggpu.iloc[290:int((original_dataset.shape[0]+290)*factor)].values.reshape(-1,1))\n",
    "prophet_results[\"pred_norm_gpu\"] = scaler_prophet.transform(prophet_results[\"pred_gpu\"].values.reshape(-1,1))\n",
    "prophet_results[\"true_norm_gpu\"] = hbnn_results[\"true_norm_gpu\"].values\n",
    "\n",
    "for target in target_qos:\n",
    "    alpa = float(int(target)/100)\n",
    "    prophet_results[f\"ub_{target}\"] = prophet_results.apply(lambda row: find_upper_bound(row[\"pred_gpu\"], row[\"pred_std\"], alpha=alpa), axis=1)\n",
    "    prophet_results[f\"ub_{target}_norm\"] = scaler_prophet.transform(prophet_results[f\"ub_{target}\"].values.reshape(-1,1))\n",
    "    prophet_results[f\"pred_n_gpu_{target}\"] = prophet_results.apply(lambda row: math.ceil(row[f\"ub_{target}\"]/gpu_no_norm_conv_value), axis=1)\n",
    "prophet_results.to_csv(\"scenarios/prophet_results.csv\")\n",
    "prophet_results.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T12:44:38.682900118Z",
     "start_time": "2023-06-29T12:44:35.437983828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Accuracy</h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def calculate_accuracy(df_results, tg):\n",
    "\n",
    "    if tg == \"NO_QOS\":\n",
    "        col = \"pred_norm_gpu\";\n",
    "    else:\n",
    "        col = f\"ub_{tg}_norm\"\n",
    "    mse_value = mean_squared_error(df_results[col].values, df_results[\"true_norm_gpu\"].values)\n",
    "    mae_value = mean_absolute_error(df_results[col].values, df_results[\"true_norm_gpu\"].values)\n",
    "    return mse_value, mae_value\n",
    "\n",
    "def calculate_success(df_results, tg):\n",
    "    sr_value = sum(df_results[f\"ub_{tg}\"]>df_results.true_gpu)/df_results.shape[0]\n",
    "\n",
    "\n",
    "    up_value = sum((df_results[f\"ub_{tg}\"]<df_results.true_gpu)*(df_results.true_gpu-df_results[f\"ub_{tg}\"]))/sum(df_results.true_gpu)\n",
    "    op_value = sum((df_results[f\"ub_{tg}\"]>df_results.true_gpu)*(df_results[f\"ub_{tg}\"]-df_results.true_gpu))/sum(df_results.true_gpu)\n",
    "    return sr_value, up_value, op_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T10:59:05.491918333Z",
     "start_time": "2023-07-01T10:59:05.465251648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "models = {\"MCDLSTM\": monte_results,\n",
    "          \"HBNN\": hbnn_results,\n",
    "          \"HBNN++\": flbnn_results,\n",
    "          \"LSTMQ\": lstmq_results,\n",
    "          \"LSTM\": lstm_results,\n",
    "          \"PROPHET\": prophet_results\n",
    "          }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T10:59:06.722037100Z",
     "start_time": "2023-07-01T10:59:06.620308172Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCDLSTM\n",
      "HBNN\n",
      "HBNN++\n",
      "LSTMQ\n",
      "LSTM\n",
      "PROPHET\n"
     ]
    }
   ],
   "source": [
    "mse_column = []\n",
    "mae_column = []\n",
    "model_column = []\n",
    "target_column = []\n",
    "for model in models:\n",
    "    print(model)\n",
    "    target_column.append(\"NO_QOS\")\n",
    "    model_column.append(model)\n",
    "    a, b = calculate_accuracy(models[model], \"NO_QOS\")\n",
    "    mse_column.append(a)\n",
    "    mae_column.append(b)\n",
    "\n",
    "    for target in target_qos:\n",
    "        if model == \"LSTMQ\":\n",
    "            a, b = \"NA\", \"NA\"\n",
    "        else:\n",
    "            a, b = calculate_accuracy(models[model], target)\n",
    "        mse_column.append(a)\n",
    "        mae_column.append(b)\n",
    "        model_column.append(model)\n",
    "        target_column.append(target)\n",
    "\n",
    "d = {\"model\": model_column,\n",
    "     \"qos\": target_column,\n",
    "     \"mse\": mse_column,\n",
    "     \"mae\": mae_column\n",
    "     }\n",
    "df_accuracy = pd.DataFrame(data=d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:20:46.478463081Z",
     "start_time": "2023-07-01T15:20:46.390580749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "     model     qos       mse       mae\n0  MCDLSTM  NO_QOS  0.002068  0.033906",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>qos</th>\n      <th>mse</th>\n      <th>mae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MCDLSTM</td>\n      <td>NO_QOS</td>\n      <td>0.002068</td>\n      <td>0.033906</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:20:49.147047703Z",
     "start_time": "2023-07-01T15:20:49.138315955Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCDLSTM\n",
      "HBNN\n",
      "HBNN++\n",
      "LSTMQ\n",
      "LSTM\n",
      "PROPHET\n"
     ]
    }
   ],
   "source": [
    "sr_column = []\n",
    "up_column = []\n",
    "op_column = []\n",
    "model_column = []\n",
    "target_column = []\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for target in target_qos:\n",
    "        a, b, c = calculate_success(models[model], target)\n",
    "        sr_column.append(a)\n",
    "        up_column.append(b)\n",
    "        op_column.append(c)\n",
    "        model_column.append(model)\n",
    "        target_column.append(target)\n",
    "d = {\"model\": model_column,\n",
    "     \"qos\": target_column,\n",
    "     \"SR\": sr_column,\n",
    "     \"UP\": up_column,\n",
    "     \"OP\": op_column\n",
    "     }\n",
    "df_success = pd.DataFrame(data=d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T12:44:55.832730228Z",
     "start_time": "2023-06-29T12:44:55.721959002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "df_accuracy.to_csv(\"accuracy_table.csv\", index=False)\n",
    "df_success.to_csv(\"success_table.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T15:24:14.808173258Z",
     "start_time": "2023-07-01T15:24:14.793882643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:07:53.551896398Z",
     "start_time": "2023-06-29T13:07:53.534952211Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
